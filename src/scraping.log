2023-11-26 11:23:47,891 [ERROR]: An error occurred: name 'Scraper' is not defined
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 17, in main
    scraper = Scraper()
              ^^^^^^^
NameError: name 'Scraper' is not defined
2023-11-26 11:24:11,613 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
2023-11-26 11:26:30,152 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO INCR' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO INCR' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO INCR' at line 1
2023-11-26 11:26:41,597 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTOINCRE' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTOINCRE' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTOINCRE' at line 1
2023-11-26 11:27:11,670 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
2023-11-26 20:15:16,582 [ERROR]: An error occurred: 'Scraper4' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 30, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper4' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-26 20:15:48,059 [INFO]: Scraping and storing data completed successfully.
2023-11-26 20:16:57,169 [INFO]: Scraping and storing data completed successfully.
2023-11-26 20:26:18,470 [ERROR]: An error occurred: cannot access local variable 'continue_to_next_name' where it is not associated with a value
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_names():
  File "/home/terence/projects/corey-scraping/src/scraping/scraper6.py", line 116, in scrape_with_names
    if continue_to_next_name:
       ^^^^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'continue_to_next_name' where it is not associated with a value
2023-11-27 22:08:00,632 [ERROR]: An error occurred: 'Scraper8' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper8' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-27 22:08:55,609 [ERROR]: An error occurred: name 'HTMLSession' is not defined
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 35, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 139, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 130, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 52, in scrape_single
    session = HTMLSession()
              ^^^^^^^^^^^
NameError: name 'HTMLSession' is not defined
2023-11-27 22:26:22,555 [ERROR]: An error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 35, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 139, in scrape_with_refcodes
    for code in refcodes:
        ^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 130, in scrape_single_thread
    time.sleep(0.3)
             ^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 53, in scrape_single
    # session = HTMLSession()
               ^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2023-11-27 22:54:17,317 [ERROR]: An error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 35, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 140, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 131, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 54, in scrape_single
    response = self.session.post(f'{url}?RefCode={data['refCode']}',headers=headers,allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2023-11-27 23:37:57,325 [ERROR]: An error occurred: 'Scraper9' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 36, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper9' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-28 00:03:09,445 [ERROR]: An error occurred: 'Scraper3' object has no attribute 'scrape_with_names'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 37, in main
    for batch_results in scraper.scrape_with_names():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper3' object has no attribute 'scrape_with_names'. Did you mean: 'scrape_with_refcodes'?
2023-11-28 00:03:46,521 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 36, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 140, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 131, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 101, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
