2023-11-26 11:23:47,891 [ERROR]: An error occurred: name 'Scraper' is not defined
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 17, in main
    scraper = Scraper()
              ^^^^^^^
NameError: name 'Scraper' is not defined
2023-11-26 11:24:11,613 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
2023-11-26 11:26:30,152 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO INCR' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO INCR' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO INCR' at line 1
2023-11-26 11:26:41,597 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTOINCRE' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTOINCRE' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTOINCRE' at line 1
2023-11-26 11:27:11,670 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 639, in cmd_query
    self._cmysql.query(
_mysql_connector.MySQLInterfaceError: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 16, in __init__
    self.cursor.execute(f'''
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/cursor_cext.py", line 330, in execute
    result = self._cnx.cmd_query(
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 647, in cmd_query
    raise get_mysql_exception(
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '['scraper2_info'] (
                                id INT PRIMARY KEY AUTO_INCR' at line 1
2023-11-26 20:15:16,582 [ERROR]: An error occurred: 'Scraper4' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 30, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper4' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-26 20:15:48,059 [INFO]: Scraping and storing data completed successfully.
2023-11-26 20:16:57,169 [INFO]: Scraping and storing data completed successfully.
2023-11-26 20:26:18,470 [ERROR]: An error occurred: cannot access local variable 'continue_to_next_name' where it is not associated with a value
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_names():
  File "/home/terence/projects/corey-scraping/src/scraping/scraper6.py", line 116, in scrape_with_names
    if continue_to_next_name:
       ^^^^^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'continue_to_next_name' where it is not associated with a value
2023-11-27 22:08:00,632 [ERROR]: An error occurred: 'Scraper8' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper8' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-27 22:08:55,609 [ERROR]: An error occurred: name 'HTMLSession' is not defined
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 35, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 139, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 130, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 52, in scrape_single
    session = HTMLSession()
              ^^^^^^^^^^^
NameError: name 'HTMLSession' is not defined
2023-11-27 22:26:22,555 [ERROR]: An error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 35, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 139, in scrape_with_refcodes
    for code in refcodes:
        ^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 130, in scrape_single_thread
    time.sleep(0.3)
             ^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 53, in scrape_single
    # session = HTMLSession()
               ^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2023-11-27 22:54:17,317 [ERROR]: An error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 35, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 140, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 131, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 54, in scrape_single
    response = self.session.post(f'{url}?RefCode={data['refCode']}',headers=headers,allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2023-11-27 23:37:57,325 [ERROR]: An error occurred: 'Scraper9' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 36, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper9' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-28 00:03:09,445 [ERROR]: An error occurred: 'Scraper3' object has no attribute 'scrape_with_names'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 37, in main
    for batch_results in scraper.scrape_with_names():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper3' object has no attribute 'scrape_with_names'. Did you mean: 'scrape_with_refcodes'?
2023-11-28 00:03:46,521 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 36, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 140, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 131, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper3.py", line 101, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-30 17:55:48,613 [ERROR]: An error occurred: string indices must be integers, not 'str'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 37, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 125, in scrape_with_refcodes
    batch_results = [result for result in executor.map(scrape_single_thread,refcodes[i:i+batch_size]) if result is not None]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/terence/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 115, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 70, in scrape_single
    response = requests.post(url, headers=headers,cookies=self.extracted_cookies, data=data, proxies=proxies, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/sessions.py", line 473, in prepare_request
    cookies = cookiejar_from_dict(cookies)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/terence/venvs/scraping/lib/python3.12/site-packages/requests/cookies.py", line 537, in cookiejar_from_dict
    cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))
                                             ~~~~~~~~~~~^^^^^^
TypeError: string indices must be integers, not 'str'
2023-11-30 18:45:51,017 [ERROR]: An error occurred: 'Scraper4' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 37, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper4' object has no attribute 'scrape_with_refcodes'. Did you mean: 'scrape_with_names'?
2023-11-30 18:46:02,414 [INFO]: Scraping and storing data completed successfully.
2023-11-30 19:56:35,181 [INFO]: Scraping and storing data completed successfully.
2023-11-30 20:01:05,199 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 42, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 34, in store_data
    for data in data_list:
TypeError: 'NoneType' object is not iterable
2023-12-01 18:58:58,557 [ERROR]: An error occurred: 'Scraper2' object has no attribute 'scrape_with_names'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 46, in main
    for batch_results in scraper.scrape_with_names():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper2' object has no attribute 'scrape_with_names'. Did you mean: 'scrape_with_refcodes'?
2023-12-01 18:59:37,811 [ERROR]: An error occurred: 'Scraper2' object has no attribute 'scrape'
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 47, in main
    for batch_results in scraper.scrape():
                         ^^^^^^^^^^^^^^
AttributeError: 'Scraper2' object has no attribute 'scrape'. Did you mean: 'scraper'?
2023-12-01 18:59:51,488 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 47, in main
    for batch_results in scraper.scrape():
TypeError: 'NoneType' object is not iterable
2023-12-01 19:15:14,397 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 47, in main
    for batch_results in scraper.scrape():
TypeError: 'NoneType' object is not iterable
2023-12-01 19:39:48,426 [ERROR]: An error occurred: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 51, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 38, in store_data
    ''', (data['first_name'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-12-01 19:55:12,416 [ERROR]: An error occurred: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 51, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 38, in store_data
    ''', (data['first_name'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-12-01 20:00:23,745 [ERROR]: An error occurred: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 51, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 38, in store_data
    ''', (data['first_name'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-12-01 20:29:55,737 [ERROR]: An error occurred: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 51, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/home/terence/projects/corey-scraping/src/database/database_handler_local.py", line 38, in store_data
    ''', (data['first_name'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-12-01 20:41:30,801 [ERROR]: An error occurred: 'method' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 33, in main
    scraper = Scraper()
              ^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 24, in __init__
    self.renew_cookies()
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 37, in renew_cookies
    for name,value in response.cookies.items:
TypeError: 'method' object is not iterable
2023-12-01 20:42:22,293 [ERROR]: An error occurred: 'method' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 33, in main
    scraper = Scraper()
              ^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 24, in __init__
    self.renew_cookies()
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 38, in renew_cookies
    for name,value in response.cookies.items:
TypeError: 'method' object is not iterable
2023-12-01 20:42:57,639 [ERROR]: An error occurred: 'method' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 33, in main
    scraper = Scraper()
              ^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 24, in __init__
    self.renew_cookies()
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 38, in renew_cookies
    for name,value in response.cookies.items:
TypeError: 'method' object is not iterable
2023-12-01 20:44:06,853 [ERROR]: An error occurred: 'method' object is not iterable
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 33, in main
    scraper = Scraper()
              ^^^^^^^^^
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 25, in __init__
    self.renew_cookies()
  File "/home/terence/projects/corey-scraping/src/scraping/scraper2.py", line 39, in renew_cookies
    for name,value in response.cookies.items:
TypeError: 'method' object is not iterable
2023-12-01 20:44:32,330 [ERROR]: An error occurred: object of type 'generator' has no len()
Traceback (most recent call last):
  File "/home/terence/projects/corey-scraping/src/main_test.py", line 51, in main
    if len(batch_results) == 0:
       ^^^^^^^^^^^^^^^^^^
TypeError: object of type 'generator' has no len()
