2023-11-15 17:23:29,975 [ERROR]: An error occurred: [Errno 2] No such file or directory: 'refcodes.txt'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 68, in scrape_with_refcodes
    with open(refcodes_file,'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'refcodes.txt'
2023-11-15 17:24:08,961 [ERROR]: An error occurred: 'Scraper1' object has no attribute 'url'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
                                ^^^^^^^^
AttributeError: 'Scraper1' object has no attribute 'url'
2023-11-15 17:24:38,086 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:24:59,862 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:30:50,656 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:41:01,449 [ERROR]: An error occurred: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 106, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    first_name = first_name_el.text.strip()
                 ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 2428, in __getattr__
    raise AttributeError(
AttributeError: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
2023-11-15 17:47:19,951 [INFO]: package: mysql.connector.plugins
2023-11-15 17:47:19,951 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:47:19,952 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:47:19,954 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AUTOINCREMENT,
                                first_name VARCHAR(255),
        ' at line 2
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 28, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 16, in __init__
    self.cursor.execute('''
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/cursor.py", line 617, in execute
    self._handle_result(self._connection.cmd_query(stmt))
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 1069, in cmd_query
    result = self._handle_result(self._send_cmd(ServerCmd.QUERY, query))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 846, in _handle_result
    raise get_exception(packet)
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AUTOINCREMENT,
                                first_name VARCHAR(255),
        ' at line 2
2023-11-15 17:49:13,074 [INFO]: package: mysql.connector.plugins
2023-11-15 17:49:13,075 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:49:13,076 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:49:13,109 [ERROR]: An error occurred: 'firstname'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 37, in main
    db_handler.store_data(data1)
  File "/root/projects/corey/src/database/database_handler.py", line 38, in store_data
    ''', (data['firstname'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^
KeyError: 'firstname'
2023-11-15 17:50:13,096 [INFO]: package: mysql.connector.plugins
2023-11-15 17:50:13,096 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:50:13,097 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:50:13,111 [INFO]: Scraping and storing data completed successfully.
2023-11-15 17:51:05,400 [INFO]: package: mysql.connector.plugins
2023-11-15 17:51:05,401 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:51:05,401 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:51:05,414 [INFO]: Scraping and storing data completed successfully.
2023-11-15 17:59:32,010 [INFO]: package: mysql.connector.plugins
2023-11-15 17:59:32,011 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:59:32,011 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:59:32,024 [INFO]: Scraping and storing data completed successfully.
2023-11-15 18:38:21,721 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:38:43,037 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:41:36,095 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:42:55,182 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:45:05,663 [INFO]: Scraping and storing data completed successfully.
2023-11-15 19:05:35,285 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper2.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-15 19:18:14,921 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 24, in main
    data1 = scraper3.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:08:33,995 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 106, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 43, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:09:23,556 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:25:10,553 [INFO]: package: mysql.connector.plugins
2023-11-16 08:25:10,554 [INFO]: plugin_name: caching_sha2_password
2023-11-16 08:25:10,555 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 08:25:10,556 [INFO]: package: mysql.connector.plugins
2023-11-16 08:25:10,556 [INFO]: plugin_name: mysql_native_password
2023-11-16 08:25:10,556 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 08:25:10,580 [INFO]: Scraping and storing data completed successfully.
2023-11-16 09:17:36,515 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 44, in scrape_single
    first_name_el = soup.select("#firstName")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 09:29:03,882 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    first_name_el = soup.select("#firstName")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 09:40:28,653 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 35, in scrape_single
    csrf_token = soup.find('meta',{'name':'csrf-token'})['content']
                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 09:43:06,185 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 126, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 63, in scrape_single
    first_name_el = soup.select_one("#firstName")['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 10:05:00,405 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:06:21,463 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:08:38,495 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:14:16,485 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:14:24,397 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:15:02,047 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:16:18,216 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:17:25,488 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    state_el = soup.select_one("#state")['value']
               ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-16 10:20:20,948 [ERROR]: An error occurred: 'str' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    first_name = first_name_el.text.strip()
                 ^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'text'
2023-11-16 10:21:37,887 [INFO]: package: mysql.connector.plugins
2023-11-16 10:21:37,887 [INFO]: plugin_name: caching_sha2_password
2023-11-16 10:21:37,887 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 10:21:37,888 [INFO]: package: mysql.connector.plugins
2023-11-16 10:21:37,888 [INFO]: plugin_name: mysql_native_password
2023-11-16 10:21:37,888 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 10:21:37,903 [INFO]: Scraping and storing data completed successfully.
2023-11-16 10:25:06,304 [ERROR]: An error occurred: 1
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    state_el = soup.select_one("#state option[selected]")[1].text
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 1
2023-11-16 10:30:58,571 [INFO]: package: mysql.connector.plugins
2023-11-16 10:30:58,571 [INFO]: plugin_name: caching_sha2_password
2023-11-16 10:30:58,572 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 10:30:58,572 [INFO]: package: mysql.connector.plugins
2023-11-16 10:30:58,573 [INFO]: plugin_name: mysql_native_password
2023-11-16 10:30:58,573 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 10:30:58,583 [INFO]: Scraping and storing data completed successfully.
2023-11-16 15:22:02,532 [INFO]: package: mysql.connector.plugins
2023-11-16 15:22:02,533 [INFO]: plugin_name: caching_sha2_password
2023-11-16 15:22:02,533 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 15:22:02,534 [INFO]: package: mysql.connector.plugins
2023-11-16 15:22:02,534 [INFO]: plugin_name: mysql_native_password
2023-11-16 15:22:02,534 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 15:22:02,547 [INFO]: Scraping and storing data completed successfully.
2023-11-16 16:22:41,568 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 46, in scrape_single
    first_name_el = soup.select_one("#firstName")['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:23:11,993 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:23:31,118 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:32:41,969 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:34:59,917 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:43:37,734 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 110, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 44, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:56:05,608 [ERROR]: An error occurred: 'Response' object has no attribute 'header'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    redirect_url = response.header['Location']
                   ^^^^^^^^^^^^^^^
AttributeError: 'Response' object has no attribute 'header'. Did you mean: 'headers'?
2023-11-16 16:56:28,219 [ERROR]: An error occurred: 'location'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    redirect_url = response.headers['Location']
                   ~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/structures.py", line 52, in __getitem__
    return self._store[key.lower()][1]
           ~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'location'
2023-11-16 16:57:11,265 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 46, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:58:18,626 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 46, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:04:17,928 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:05:03,972 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:20:48,915 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 116, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:21:24,353 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:27:40,451 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:29:10,556 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 48, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:31:25,821 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 48, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:41:34,966 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 52, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:56:45,530 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:57:05,786 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:08:22,932 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:09:11,792 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:10:45,775 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:12:03,399 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:24:37,965 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:25:28,105 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:25:59,854 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:41:52,482 [INFO]: Starting Chromium download.
2023-11-16 20:42:23,637 [INFO]: Beginning extraction
2023-11-16 20:42:25,489 [INFO]: Chromium extracted to: /root/.local/share/pyppeteer/local-chromium/588429
2023-11-16 20:42:25,800 [INFO]: Browser listening on: ws://127.0.0.1:43131/devtools/browser/a9d855d5-19f9-435d-ad9d-5b06ce3280f3
2023-11-16 20:42:30,009 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:42:30,011 [INFO]: terminate chrome process...
2023-11-16 20:45:04,780 [INFO]: Browser listening on: ws://127.0.0.1:43375/devtools/browser/a64d8c9c-fdab-4dd4-84c2-896fbaf26c63
2023-11-16 20:45:10,945 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:45:10,947 [INFO]: terminate chrome process...
2023-11-16 20:48:38,029 [INFO]: Browser listening on: ws://127.0.0.1:46737/devtools/browser/065861ec-5d42-4327-bb47-d9b9b1002074
2023-11-16 20:48:41,964 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:48:41,966 [INFO]: terminate chrome process...
2023-11-16 21:10:20,904 [INFO]: Browser listening on: ws://127.0.0.1:58309/devtools/browser/ad398b31-18a5-473f-a5fb-b7eb43abf104
2023-11-16 21:10:24,886 [ERROR]: An error occurred: 'list' object has no attribute 'find'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input=[name="wpforms[fields][1]"]',first=True).attrs['value'] = data['refCode']
    ^^^^^^^^^
AttributeError: 'list' object has no attribute 'find'
2023-11-16 21:10:24,889 [INFO]: terminate chrome process...
2023-11-16 21:12:57,184 [INFO]: Browser listening on: ws://127.0.0.1:52593/devtools/browser/4455ea81-8f7f-4113-840c-4af9b71af0ba
2023-11-16 21:13:01,965 [ERROR]: An error occurred: 'list' object has no attribute 'find'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input=[name="wpforms[fields][1]"]',first=True).attrs['value'] = data['refCode']
    ^^^^^^^^^
AttributeError: 'list' object has no attribute 'find'
2023-11-16 21:13:01,966 [INFO]: terminate chrome process...
2023-11-16 21:14:10,225 [INFO]: Browser listening on: ws://127.0.0.1:33365/devtools/browser/2b599bdf-14aa-457d-8ab3-4d0eb78f62dd
2023-11-16 21:14:13,868 [ERROR]: An error occurred: Expected selector, got <DELIM '=' at 5>
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input=[name="wpforms[fields][1]"]',first=True).attrs['value'] = data['refCode']
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests_html.py", line 212, in find
    for found in self.pq(selector)
                 ^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 256, in __call__
    result = self._copy(*args, parent=self, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 242, in _copy
    return self.__class__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 227, in __init__
    xpath = self._css_to_xpath(selector)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 238, in _css_to_xpath
    return self._translator.css_to_xpath(selector, prefix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/xpath.py", line 224, in css_to_xpath
    for selector in parse(css)
                    ^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 543, in parse
    return list(parse_selector_group(stream))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 558, in parse_selector_group
    yield Selector(*parse_selector(stream))
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 567, in parse_selector
    result, pseudo_element = parse_simple_selector(stream)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 700, in parse_simple_selector
    raise SelectorSyntaxError("Expected selector, got %s" % (peek,))
cssselect.parser.SelectorSyntaxError: Expected selector, got <DELIM '=' at 5>
2023-11-16 21:14:13,871 [INFO]: terminate chrome process...
2023-11-16 21:16:47,049 [INFO]: Browser listening on: ws://127.0.0.1:49713/devtools/browser/059dc3c0-4d46-4fb8-959c-ba39cfec2870
2023-11-16 21:16:50,447 [ERROR]: An error occurred: 'Element' object has no attribute 'submit'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 41, in scrape_single
    response = form.submit()
               ^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'submit'
2023-11-16 21:16:50,450 [INFO]: terminate chrome process...
2023-11-16 21:24:02,257 [INFO]: Browser listening on: ws://127.0.0.1:41945/devtools/browser/f884f73d-f256-4b79-873a-a962b76546c9
2023-11-16 21:24:06,316 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    e.attrs['name'] : e.attrs['value'] for e in form.find('input')
                      ~~~~~~~^^^^^^^^^
KeyError: 'value'
2023-11-16 21:24:06,317 [INFO]: terminate chrome process...
2023-11-16 21:27:01,379 [INFO]: Browser listening on: ws://127.0.0.1:47361/devtools/browser/a95721c1-7edb-4a60-b366-fe22f675bfe9
2023-11-16 21:27:05,841 [ERROR]: An error occurred: Invalid URL '/': No scheme supplied. Perhaps you meant https:///?
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    response = session.post(post_url)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL '/': No scheme supplied. Perhaps you meant https:///?
2023-11-16 21:27:05,844 [INFO]: terminate chrome process...
2023-11-16 21:28:08,068 [INFO]: Browser listening on: ws://127.0.0.1:39659/devtools/browser/dd222181-ab5a-48d7-b97a-0e7d0c72aded
2023-11-16 21:28:13,342 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 21:28:13,344 [INFO]: terminate chrome process...
2023-11-16 21:28:46,368 [INFO]: Browser listening on: ws://127.0.0.1:55173/devtools/browser/742bae92-b46b-47e2-a126-426d289cf920
2023-11-16 21:28:50,814 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 21:28:50,816 [INFO]: terminate chrome process...
2023-11-16 21:29:54,586 [INFO]: Browser listening on: ws://127.0.0.1:34707/devtools/browser/a9ed0081-50a9-4e0e-accc-e5de85f5384d
2023-11-16 21:29:59,337 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 21:29:59,339 [INFO]: terminate chrome process...
2023-11-16 21:34:09,444 [INFO]: Browser listening on: ws://127.0.0.1:46921/devtools/browser/1a17da75-bcba-40cb-9660-79afb008fb3c
2023-11-16 21:34:12,928 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'wpforms[fields][1]':data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:34:12,930 [INFO]: terminate chrome process...
2023-11-16 21:36:15,433 [INFO]: Browser listening on: ws://127.0.0.1:35847/devtools/browser/52df5a1d-6b37-460f-b506-d20435269bfb
2023-11-16 21:36:19,519 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'wpforms[fields][1]':data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:36:19,522 [INFO]: terminate chrome process...
2023-11-16 21:38:36,370 [INFO]: Browser listening on: ws://127.0.0.1:52297/devtools/browser/0b7764f2-fe0f-4ca1-a407-e0ed9ce0caa3
2023-11-16 21:38:39,661 [ERROR]: An error occurred: 'Element' object has no attribute 'form'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 38, in scrape_single
    form = response.html.find('#wpforms-form-4251', first=True).form
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'form'
2023-11-16 21:38:39,662 [INFO]: terminate chrome process...
2023-11-16 21:43:58,235 [INFO]: Browser listening on: ws://127.0.0.1:44459/devtools/browser/b7bf8e31-b1d9-4e34-8727-17e3fe7eb14f
2023-11-16 21:44:02,186 [ERROR]: An error occurred: BaseParser.find() got an unexpected keyword argument 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find(attrs={'name':'wpforms[fields][1]'})['value'] = data['refCode']
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseParser.find() got an unexpected keyword argument 'attrs'
2023-11-16 21:44:02,188 [INFO]: terminate chrome process...
2023-11-16 21:44:47,469 [INFO]: Browser listening on: ws://127.0.0.1:39835/devtools/browser/b9358fe7-6c4e-4331-b00c-99c243925a90
2023-11-16 21:44:51,027 [ERROR]: An error occurred: Expected ']', got <EOF at 31>
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input[name="wpforms[fields][1]"')['value'] = data['refCode']
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests_html.py", line 212, in find
    for found in self.pq(selector)
                 ^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 256, in __call__
    result = self._copy(*args, parent=self, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 242, in _copy
    return self.__class__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 227, in __init__
    xpath = self._css_to_xpath(selector)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 238, in _css_to_xpath
    return self._translator.css_to_xpath(selector, prefix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/xpath.py", line 224, in css_to_xpath
    for selector in parse(css)
                    ^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 543, in parse
    return list(parse_selector_group(stream))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 558, in parse_selector_group
    yield Selector(*parse_selector(stream))
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 567, in parse_selector
    result, pseudo_element = parse_simple_selector(stream)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 634, in parse_simple_selector
    result = parse_attrib(result, stream)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 802, in parse_attrib
    raise SelectorSyntaxError("Expected ']', got %s" % (next,))
cssselect.parser.SelectorSyntaxError: Expected ']', got <EOF at 31>
2023-11-16 21:44:51,030 [INFO]: terminate chrome process...
2023-11-16 21:46:46,368 [INFO]: Browser listening on: ws://127.0.0.1:39231/devtools/browser/25167be1-c4c1-4263-8789-e21e66e34554
2023-11-16 21:46:49,704 [ERROR]: An error occurred: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input[name="wpforms[fields][1]"]')['value'] = data['refCode']
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-11-16 21:46:49,706 [INFO]: terminate chrome process...
2023-11-16 21:47:39,731 [INFO]: Browser listening on: ws://127.0.0.1:42159/devtools/browser/6d4780ff-544b-44ce-9a9f-fca5202c7411
2023-11-16 21:47:43,271 [ERROR]: An error occurred: 'Element' object has no attribute 'submit'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    response = form.submit()
               ^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'submit'
2023-11-16 21:47:43,279 [INFO]: terminate chrome process...
2023-11-16 21:50:13,971 [INFO]: Browser listening on: ws://127.0.0.1:48893/devtools/browser/dab3472e-419d-49f8-8915-4f8ef1f29c3c
2023-11-16 21:50:18,022 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'input[name="wpforms[fields][1]"]':data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:50:18,024 [INFO]: terminate chrome process...
2023-11-16 21:56:09,119 [INFO]: Browser listening on: ws://127.0.0.1:43535/devtools/browser/980dd5e1-7e61-4df6-97ef-6c38ccf87354
2023-11-16 21:56:12,641 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:56:12,643 [INFO]: terminate chrome process...
2023-11-16 21:57:56,028 [INFO]: Browser listening on: ws://127.0.0.1:56633/devtools/browser/cda93083-a21e-4ff4-a08d-d34e200922bf
2023-11-16 21:57:59,432 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 40, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:57:59,434 [INFO]: terminate chrome process...
2023-11-16 21:58:21,114 [INFO]: Browser listening on: ws://127.0.0.1:58709/devtools/browser/bb969dc2-f084-47c4-b176-0f80e6207cf6
2023-11-16 21:58:25,219 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 40, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:58:25,221 [INFO]: terminate chrome process...
2023-11-16 22:00:50,569 [INFO]: Browser listening on: ws://127.0.0.1:41955/devtools/browser/006738c1-3f8a-449d-82f3-22e0ab32ceb9
2023-11-16 22:00:54,621 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 40, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 22:00:54,623 [INFO]: terminate chrome process...
2023-11-16 22:06:23,424 [INFO]: Browser listening on: ws://127.0.0.1:43367/devtools/browser/25c7f503-9f30-47d8-a868-39e4ade55fe7
2023-11-16 22:06:27,060 [ERROR]: An error occurred: 'FormElement' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 41, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'FormElement' object has no attribute 'input'. Did you mean: 'inputs'?
2023-11-16 22:06:27,065 [INFO]: terminate chrome process...
2023-11-16 22:09:40,493 [INFO]: Browser listening on: ws://127.0.0.1:40237/devtools/browser/557a630c-276a-4ae3-917e-6240b06cec5d
2023-11-16 22:09:43,931 [ERROR]: An error occurred: 'Element' object has no attribute 'inputs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    inputs = form_el.inputs
             ^^^^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'inputs'
2023-11-16 22:09:43,934 [INFO]: terminate chrome process...
2023-11-17 15:55:03,544 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 54, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-17 16:17:37,123 [ERROR]: An error occurred: 2003 (HY000): Can't connect to MySQL server on '103.40.3.37:3306' (110)
Traceback (most recent call last):
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 308, in _open_connection
    self._cmysql.connect(**cnx_kwargs)
_mysql_connector.MySQLInterfaceError: Can't connect to MySQL server on '103.40.3.37:3306' (110)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/pooling.py", line 293, in connect
    return CMySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 129, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 1237, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 313, in _open_connection
    raise get_mysql_exception(
mysql.connector.errors.DatabaseError: 2003 (HY000): Can't connect to MySQL server on '103.40.3.37:3306' (110)
2023-11-17 16:21:02,866 [INFO]: Scraping and storing data completed successfully.
2023-11-17 19:01:39,489 [INFO]: package: mysql.connector.plugins
2023-11-17 19:01:39,489 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:01:39,491 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:01:41,318 [ERROR]: An error occurred: Scraper1.generate_code() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 104, in scrape_with_refcodes
    refcodes = self.generate_code(2,222000)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Scraper1.generate_code() takes 2 positional arguments but 3 were given
2023-11-17 19:02:35,629 [INFO]: package: mysql.connector.plugins
2023-11-17 19:02:35,630 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:02:35,631 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:02:41,216 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    state_el = soup.select("#state option[selected]")[1].text
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-17 19:04:11,659 [INFO]: package: mysql.connector.plugins
2023-11-17 19:04:11,660 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:04:11,664 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:15:04,206 [INFO]: package: mysql.connector.plugins
2023-11-17 19:15:04,206 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:15:04,208 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:54:46,324 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 119, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-17 20:02:32,798 [INFO]: package: mysql.connector.plugins
2023-11-17 20:02:32,800 [INFO]: plugin_name: caching_sha2_password
2023-11-17 20:02:32,807 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 20:57:19,732 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 48, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-17 20:59:57,344 [INFO]: package: mysql.connector.plugins
2023-11-17 20:59:57,345 [INFO]: plugin_name: caching_sha2_password
2023-11-17 20:59:57,349 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 21:57:45,607 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 119, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 19:28:48,167 [INFO]: package: mysql.connector.plugins
2023-11-18 19:28:48,168 [INFO]: plugin_name: caching_sha2_password
2023-11-18 19:28:48,172 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 20:26:56,014 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 21:20:44,952 [INFO]: package: mysql.connector.plugins
2023-11-18 21:20:44,952 [INFO]: plugin_name: caching_sha2_password
2023-11-18 21:20:44,955 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 21:27:24,336 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper2.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 52, in scrape_single
    state_el = soup.select("#state option[selected]")[1].text if soup.select("#state option[selected]") else None
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-18 21:28:22,157 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper2.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 52, in scrape_single
    state_el = soup.select("#state option[selected]")[1].text if soup.select("#state option[selected]") else None
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-18 22:17:46,901 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 22:18:16,792 [INFO]: package: mysql.connector.plugins
2023-11-18 22:18:16,793 [INFO]: plugin_name: caching_sha2_password
2023-11-18 22:18:16,796 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 22:18:16,805 [INFO]: package: mysql.connector.plugins
2023-11-18 22:18:16,805 [INFO]: plugin_name: mysql_native_password
2023-11-18 22:18:16,806 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-18 22:18:18,451 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 22:20:17,133 [INFO]: package: mysql.connector.plugins
2023-11-18 22:20:17,134 [INFO]: plugin_name: caching_sha2_password
2023-11-18 22:20:17,136 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 22:20:17,136 [INFO]: package: mysql.connector.plugins
2023-11-18 22:20:17,136 [INFO]: plugin_name: mysql_native_password
2023-11-18 22:20:17,137 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-18 23:04:41,604 [INFO]: package: mysql.connector.plugins
2023-11-18 23:04:41,604 [INFO]: plugin_name: caching_sha2_password
2023-11-18 23:04:41,606 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 23:18:44,575 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 23:26:44,597 [INFO]: package: mysql.connector.plugins
2023-11-18 23:26:44,598 [INFO]: plugin_name: caching_sha2_password
2023-11-18 23:26:44,603 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 23:38:42,489 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x560f0bac0fb3 <unknown>
#1 0x560f0b7944a7 <unknown>
#2 0x560f0b7c7c93 <unknown>
#3 0x560f0b7c410c <unknown>
#4 0x560f0b806ac6 <unknown>
#5 0x560f0b7fd713 <unknown>
#6 0x560f0b7d018b <unknown>
#7 0x560f0b7d0f7e <unknown>
#8 0x560f0ba868d8 <unknown>
#9 0x560f0ba8a800 <unknown>
#10 0x560f0ba94cfc <unknown>
#11 0x560f0ba8b418 <unknown>
#12 0x560f0ba5842f <unknown>
#13 0x560f0baaf4e8 <unknown>
#14 0x560f0baaf6b4 <unknown>
#15 0x560f0bac0143 <unknown>
#16 0x7f6e7d2abac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x560f0bac0fb3 <unknown>
#1 0x560f0b7944a7 <unknown>
#2 0x560f0b7c7c93 <unknown>
#3 0x560f0b7c410c <unknown>
#4 0x560f0b806ac6 <unknown>
#5 0x560f0b7fd713 <unknown>
#6 0x560f0b7d018b <unknown>
#7 0x560f0b7d0f7e <unknown>
#8 0x560f0ba868d8 <unknown>
#9 0x560f0ba8a800 <unknown>
#10 0x560f0ba94cfc <unknown>
#11 0x560f0ba8b418 <unknown>
#12 0x560f0ba5842f <unknown>
#13 0x560f0baaf4e8 <unknown>
#14 0x560f0baaf6b4 <unknown>
#15 0x560f0bac0143 <unknown>
#16 0x7f6e7d2abac3 <unknown>

2023-11-18 23:42:23,758 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5634f3a2dfb3 <unknown>
#1 0x5634f37014a7 <unknown>
#2 0x5634f3734c93 <unknown>
#3 0x5634f373110c <unknown>
#4 0x5634f3773ac6 <unknown>
#5 0x5634f376a713 <unknown>
#6 0x5634f373d18b <unknown>
#7 0x5634f373df7e <unknown>
#8 0x5634f39f38d8 <unknown>
#9 0x5634f39f7800 <unknown>
#10 0x5634f3a01cfc <unknown>
#11 0x5634f39f8418 <unknown>
#12 0x5634f39c542f <unknown>
#13 0x5634f3a1c4e8 <unknown>
#14 0x5634f3a1c6b4 <unknown>
#15 0x5634f3a2d143 <unknown>
#16 0x7f79f9550ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5634f3a2dfb3 <unknown>
#1 0x5634f37014a7 <unknown>
#2 0x5634f3734c93 <unknown>
#3 0x5634f373110c <unknown>
#4 0x5634f3773ac6 <unknown>
#5 0x5634f376a713 <unknown>
#6 0x5634f373d18b <unknown>
#7 0x5634f373df7e <unknown>
#8 0x5634f39f38d8 <unknown>
#9 0x5634f39f7800 <unknown>
#10 0x5634f3a01cfc <unknown>
#11 0x5634f39f8418 <unknown>
#12 0x5634f39c542f <unknown>
#13 0x5634f3a1c4e8 <unknown>
#14 0x5634f3a1c6b4 <unknown>
#15 0x5634f3a2d143 <unknown>
#16 0x7f79f9550ac3 <unknown>

2023-11-18 23:43:19,887 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x561825804fb3 <unknown>
#1 0x5618254d84a7 <unknown>
#2 0x56182550bc93 <unknown>
#3 0x56182550810c <unknown>
#4 0x56182554aac6 <unknown>
#5 0x561825541713 <unknown>
#6 0x56182551418b <unknown>
#7 0x561825514f7e <unknown>
#8 0x5618257ca8d8 <unknown>
#9 0x5618257ce800 <unknown>
#10 0x5618257d8cfc <unknown>
#11 0x5618257cf418 <unknown>
#12 0x56182579c42f <unknown>
#13 0x5618257f34e8 <unknown>
#14 0x5618257f36b4 <unknown>
#15 0x561825804143 <unknown>
#16 0x7fe137274ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x561825804fb3 <unknown>
#1 0x5618254d84a7 <unknown>
#2 0x56182550bc93 <unknown>
#3 0x56182550810c <unknown>
#4 0x56182554aac6 <unknown>
#5 0x561825541713 <unknown>
#6 0x56182551418b <unknown>
#7 0x561825514f7e <unknown>
#8 0x5618257ca8d8 <unknown>
#9 0x5618257ce800 <unknown>
#10 0x5618257d8cfc <unknown>
#11 0x5618257cf418 <unknown>
#12 0x56182579c42f <unknown>
#13 0x5618257f34e8 <unknown>
#14 0x5618257f36b4 <unknown>
#15 0x561825804143 <unknown>
#16 0x7fe137274ac3 <unknown>

2023-11-19 00:00:28,805 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5620a519b5e3 <unknown>
#1 0x5620a4e5e0b7 <unknown>
#2 0x5620a4e94e55 <unknown>
#3 0x5620a4e91b81 <unknown>
#4 0x5620a4edc47f <unknown>
#5 0x5620a4ed2cc3 <unknown>
#6 0x5620a4e9e0e4 <unknown>
#7 0x5620a4e9f0ae <unknown>
#8 0x5620a5161ce1 <unknown>
#9 0x5620a5165b7e <unknown>
#10 0x5620a514f4b5 <unknown>
#11 0x5620a51667d6 <unknown>
#12 0x5620a5132dbf <unknown>
#13 0x5620a5189748 <unknown>
#14 0x5620a5189917 <unknown>
#15 0x5620a519a773 <unknown>
#16 0x7fc4a185fac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5620a519b5e3 <unknown>
#1 0x5620a4e5e0b7 <unknown>
#2 0x5620a4e94e55 <unknown>
#3 0x5620a4e91b81 <unknown>
#4 0x5620a4edc47f <unknown>
#5 0x5620a4ed2cc3 <unknown>
#6 0x5620a4e9e0e4 <unknown>
#7 0x5620a4e9f0ae <unknown>
#8 0x5620a5161ce1 <unknown>
#9 0x5620a5165b7e <unknown>
#10 0x5620a514f4b5 <unknown>
#11 0x5620a51667d6 <unknown>
#12 0x5620a5132dbf <unknown>
#13 0x5620a5189748 <unknown>
#14 0x5620a5189917 <unknown>
#15 0x5620a519a773 <unknown>
#16 0x7fc4a185fac3 <unknown>

2023-11-19 00:03:09,893 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55cded7fe5e3 <unknown>
#1 0x55cded4c10b7 <unknown>
#2 0x55cded4f7e55 <unknown>
#3 0x55cded4f4b81 <unknown>
#4 0x55cded53f47f <unknown>
#5 0x55cded535cc3 <unknown>
#6 0x55cded5010e4 <unknown>
#7 0x55cded5020ae <unknown>
#8 0x55cded7c4ce1 <unknown>
#9 0x55cded7c8b7e <unknown>
#10 0x55cded7b24b5 <unknown>
#11 0x55cded7c97d6 <unknown>
#12 0x55cded795dbf <unknown>
#13 0x55cded7ec748 <unknown>
#14 0x55cded7ec917 <unknown>
#15 0x55cded7fd773 <unknown>
#16 0x7fed6c7c4ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55cded7fe5e3 <unknown>
#1 0x55cded4c10b7 <unknown>
#2 0x55cded4f7e55 <unknown>
#3 0x55cded4f4b81 <unknown>
#4 0x55cded53f47f <unknown>
#5 0x55cded535cc3 <unknown>
#6 0x55cded5010e4 <unknown>
#7 0x55cded5020ae <unknown>
#8 0x55cded7c4ce1 <unknown>
#9 0x55cded7c8b7e <unknown>
#10 0x55cded7b24b5 <unknown>
#11 0x55cded7c97d6 <unknown>
#12 0x55cded795dbf <unknown>
#13 0x55cded7ec748 <unknown>
#14 0x55cded7ec917 <unknown>
#15 0x55cded7fd773 <unknown>
#16 0x7fed6c7c4ac3 <unknown>

2023-11-19 00:05:45,508 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5611d7f455e3 <unknown>
#1 0x5611d7c080b7 <unknown>
#2 0x5611d7c3ee55 <unknown>
#3 0x5611d7c3bb81 <unknown>
#4 0x5611d7c8647f <unknown>
#5 0x5611d7c7ccc3 <unknown>
#6 0x5611d7c480e4 <unknown>
#7 0x5611d7c490ae <unknown>
#8 0x5611d7f0bce1 <unknown>
#9 0x5611d7f0fb7e <unknown>
#10 0x5611d7ef94b5 <unknown>
#11 0x5611d7f107d6 <unknown>
#12 0x5611d7edcdbf <unknown>
#13 0x5611d7f33748 <unknown>
#14 0x5611d7f33917 <unknown>
#15 0x5611d7f44773 <unknown>
#16 0x7f08c6eb4ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5611d7f455e3 <unknown>
#1 0x5611d7c080b7 <unknown>
#2 0x5611d7c3ee55 <unknown>
#3 0x5611d7c3bb81 <unknown>
#4 0x5611d7c8647f <unknown>
#5 0x5611d7c7ccc3 <unknown>
#6 0x5611d7c480e4 <unknown>
#7 0x5611d7c490ae <unknown>
#8 0x5611d7f0bce1 <unknown>
#9 0x5611d7f0fb7e <unknown>
#10 0x5611d7ef94b5 <unknown>
#11 0x5611d7f107d6 <unknown>
#12 0x5611d7edcdbf <unknown>
#13 0x5611d7f33748 <unknown>
#14 0x5611d7f33917 <unknown>
#15 0x5611d7f44773 <unknown>
#16 0x7f08c6eb4ac3 <unknown>

2023-11-19 00:07:03,572 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55be06f825e3 <unknown>
#1 0x55be06c450b7 <unknown>
#2 0x55be06c7be55 <unknown>
#3 0x55be06c78b81 <unknown>
#4 0x55be06cc347f <unknown>
#5 0x55be06cb9cc3 <unknown>
#6 0x55be06c850e4 <unknown>
#7 0x55be06c860ae <unknown>
#8 0x55be06f48ce1 <unknown>
#9 0x55be06f4cb7e <unknown>
#10 0x55be06f364b5 <unknown>
#11 0x55be06f4d7d6 <unknown>
#12 0x55be06f19dbf <unknown>
#13 0x55be06f70748 <unknown>
#14 0x55be06f70917 <unknown>
#15 0x55be06f81773 <unknown>
#16 0x7faf8bf66ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55be06f825e3 <unknown>
#1 0x55be06c450b7 <unknown>
#2 0x55be06c7be55 <unknown>
#3 0x55be06c78b81 <unknown>
#4 0x55be06cc347f <unknown>
#5 0x55be06cb9cc3 <unknown>
#6 0x55be06c850e4 <unknown>
#7 0x55be06c860ae <unknown>
#8 0x55be06f48ce1 <unknown>
#9 0x55be06f4cb7e <unknown>
#10 0x55be06f364b5 <unknown>
#11 0x55be06f4d7d6 <unknown>
#12 0x55be06f19dbf <unknown>
#13 0x55be06f70748 <unknown>
#14 0x55be06f70917 <unknown>
#15 0x55be06f81773 <unknown>
#16 0x7faf8bf66ac3 <unknown>

2023-11-19 00:07:10,333 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5631064d25e3 <unknown>
#1 0x5631061950b7 <unknown>
#2 0x5631061cbe55 <unknown>
#3 0x5631061c8b81 <unknown>
#4 0x56310621347f <unknown>
#5 0x563106209cc3 <unknown>
#6 0x5631061d50e4 <unknown>
#7 0x5631061d60ae <unknown>
#8 0x563106498ce1 <unknown>
#9 0x56310649cb7e <unknown>
#10 0x5631064864b5 <unknown>
#11 0x56310649d7d6 <unknown>
#12 0x563106469dbf <unknown>
#13 0x5631064c0748 <unknown>
#14 0x5631064c0917 <unknown>
#15 0x5631064d1773 <unknown>
#16 0x7f8c4d05eac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5631064d25e3 <unknown>
#1 0x5631061950b7 <unknown>
#2 0x5631061cbe55 <unknown>
#3 0x5631061c8b81 <unknown>
#4 0x56310621347f <unknown>
#5 0x563106209cc3 <unknown>
#6 0x5631061d50e4 <unknown>
#7 0x5631061d60ae <unknown>
#8 0x563106498ce1 <unknown>
#9 0x56310649cb7e <unknown>
#10 0x5631064864b5 <unknown>
#11 0x56310649d7d6 <unknown>
#12 0x563106469dbf <unknown>
#13 0x5631064c0748 <unknown>
#14 0x5631064c0917 <unknown>
#15 0x5631064d1773 <unknown>
#16 0x7f8c4d05eac3 <unknown>

2023-11-19 00:24:12,171 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x557056c8a5e3 <unknown>
#1 0x55705694d0b7 <unknown>
#2 0x557056983e55 <unknown>
#3 0x557056980b81 <unknown>
#4 0x5570569cb47f <unknown>
#5 0x5570569c1cc3 <unknown>
#6 0x55705698d0e4 <unknown>
#7 0x55705698e0ae <unknown>
#8 0x557056c50ce1 <unknown>
#9 0x557056c54b7e <unknown>
#10 0x557056c3e4b5 <unknown>
#11 0x557056c557d6 <unknown>
#12 0x557056c21dbf <unknown>
#13 0x557056c78748 <unknown>
#14 0x557056c78917 <unknown>
#15 0x557056c89773 <unknown>
#16 0x7f4d23851ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x557056c8a5e3 <unknown>
#1 0x55705694d0b7 <unknown>
#2 0x557056983e55 <unknown>
#3 0x557056980b81 <unknown>
#4 0x5570569cb47f <unknown>
#5 0x5570569c1cc3 <unknown>
#6 0x55705698d0e4 <unknown>
#7 0x55705698e0ae <unknown>
#8 0x557056c50ce1 <unknown>
#9 0x557056c54b7e <unknown>
#10 0x557056c3e4b5 <unknown>
#11 0x557056c557d6 <unknown>
#12 0x557056c21dbf <unknown>
#13 0x557056c78748 <unknown>
#14 0x557056c78917 <unknown>
#15 0x557056c89773 <unknown>
#16 0x7f4d23851ac3 <unknown>

2023-11-19 00:25:12,596 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 00:25:29,616 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler_local.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-19 00:25:38,386 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler_local.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-19 00:27:32,892 [ERROR]: An error occurred: 'WebDriverWait' object has no attribute 'get'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    self.br.get(url)
    ^^^^^^^^^^^
AttributeError: 'WebDriverWait' object has no attribute 'get'
2023-11-19 00:28:50,600 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 57, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 00:29:06,056 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 57, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 00:33:08,150 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x55d42dbae5e3 <unknown>
#1 0x55d42d8710b7 <unknown>
#2 0x55d42d8bef53 <unknown>
#3 0x55d42d8bf051 <unknown>
#4 0x55d42d9049c4 <unknown>
#5 0x55d42d8e5f1d <unknown>
#6 0x55d42d901b3d <unknown>
#7 0x55d42d8e5cc3 <unknown>
#8 0x55d42d8b10e4 <unknown>
#9 0x55d42d8b20ae <unknown>
#10 0x55d42db74ce1 <unknown>
#11 0x55d42db78b7e <unknown>
#12 0x55d42db624b5 <unknown>
#13 0x55d42db797d6 <unknown>
#14 0x55d42db45dbf <unknown>
#15 0x55d42db9c748 <unknown>
#16 0x55d42db9c917 <unknown>
#17 0x55d42dbad773 <unknown>
#18 0x7f5f9482bac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 129, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 52, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x55d42dbae5e3 <unknown>
#1 0x55d42d8710b7 <unknown>
#2 0x55d42d8bef53 <unknown>
#3 0x55d42d8bf051 <unknown>
#4 0x55d42d9049c4 <unknown>
#5 0x55d42d8e5f1d <unknown>
#6 0x55d42d901b3d <unknown>
#7 0x55d42d8e5cc3 <unknown>
#8 0x55d42d8b10e4 <unknown>
#9 0x55d42d8b20ae <unknown>
#10 0x55d42db74ce1 <unknown>
#11 0x55d42db78b7e <unknown>
#12 0x55d42db624b5 <unknown>
#13 0x55d42db797d6 <unknown>
#14 0x55d42db45dbf <unknown>
#15 0x55d42db9c748 <unknown>
#16 0x55d42db9c917 <unknown>
#17 0x55d42dbad773 <unknown>
#18 0x7f5f9482bac3 <unknown>

2023-11-19 00:34:06,028 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 131, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 63, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 15:53:28,221 [INFO]: package: mysql.connector.plugins
2023-11-19 15:53:28,223 [INFO]: plugin_name: caching_sha2_password
2023-11-19 15:53:28,230 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 15:53:31,593 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 124, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 15:53:57,672 [INFO]: package: mysql.connector.plugins
2023-11-19 15:53:57,672 [INFO]: plugin_name: caching_sha2_password
2023-11-19 15:53:57,674 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 15:54:01,049 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 55, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 15:56:19,285 [INFO]: package: mysql.connector.plugins
2023-11-19 15:56:19,285 [INFO]: plugin_name: caching_sha2_password
2023-11-19 15:56:19,293 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 16:15:14,815 [INFO]: package: mysql.connector.plugins
2023-11-19 16:15:14,816 [INFO]: plugin_name: caching_sha2_password
2023-11-19 16:15:14,820 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 16:15:14,834 [INFO]: package: mysql.connector.plugins
2023-11-19 16:15:14,834 [INFO]: plugin_name: mysql_native_password
2023-11-19 16:15:14,837 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-19 16:15:30,561 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 131, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 63, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 16:16:13,982 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 131, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 63, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 16:27:09,544 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 132, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 63, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value'] if soup.find(attrs={'name':'wpforms[fields][1][first]'}) else None
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 16:28:49,722 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 132, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 64, in scrape_single
    last_name_el = soup.find(attrs={'name':'wpforms[fields][1][last]'})['value'] if soup.find(attrs={'name':'wpforms[fields][1][last]'}) else None
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 16:32:15,643 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 64, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value'] if soup.find(attrs={'name':'wpforms[fields][1][first]'}) else None
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 16:43:09,625 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 65, in scrape_single
    last_name_el = soup.find(attrs={'name':'wpforms[fields][1][last]'})['value'] if soup.find(attrs={'name':'wpforms[fields][1][last]'}) else None
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-19 16:46:04,675 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 68, in scrape_single
    state_el = soup.select('select[name="wpforms[fields][4][state]"] option[selected]')[1].text if soup.select('select[name="wpforms[fields][4][state]"] option[selected]')[1] else None
                                                                                                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-19 16:50:42,490 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x560fa44bb5e3 <unknown>
#1 0x560fa417e0b7 <unknown>
#2 0x560fa41cbf53 <unknown>
#3 0x560fa41cc051 <unknown>
#4 0x560fa42119c4 <unknown>
#5 0x560fa41f2f1d <unknown>
#6 0x560fa420eb3d <unknown>
#7 0x560fa41f2cc3 <unknown>
#8 0x560fa41be0e4 <unknown>
#9 0x560fa41bf0ae <unknown>
#10 0x560fa4481ce1 <unknown>
#11 0x560fa4485b7e <unknown>
#12 0x560fa446f4b5 <unknown>
#13 0x560fa44867d6 <unknown>
#14 0x560fa4452dbf <unknown>
#15 0x560fa44a9748 <unknown>
#16 0x560fa44a9917 <unknown>
#17 0x560fa44ba773 <unknown>
#18 0x7f08e0f90ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 54, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x560fa44bb5e3 <unknown>
#1 0x560fa417e0b7 <unknown>
#2 0x560fa41cbf53 <unknown>
#3 0x560fa41cc051 <unknown>
#4 0x560fa42119c4 <unknown>
#5 0x560fa41f2f1d <unknown>
#6 0x560fa420eb3d <unknown>
#7 0x560fa41f2cc3 <unknown>
#8 0x560fa41be0e4 <unknown>
#9 0x560fa41bf0ae <unknown>
#10 0x560fa4481ce1 <unknown>
#11 0x560fa4485b7e <unknown>
#12 0x560fa446f4b5 <unknown>
#13 0x560fa44867d6 <unknown>
#14 0x560fa4452dbf <unknown>
#15 0x560fa44a9748 <unknown>
#16 0x560fa44a9917 <unknown>
#17 0x560fa44ba773 <unknown>
#18 0x7f08e0f90ac3 <unknown>

2023-11-19 16:54:20,990 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 48, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 17:07:21,026 [INFO]: package: mysql.connector.plugins
2023-11-19 17:07:21,027 [INFO]: plugin_name: caching_sha2_password
2023-11-19 17:07:21,030 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 17:07:37,090 [ERROR]: An error occurred: 'str' object has no attribute 'items'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 36, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 489, in prepare_headers
    for header in headers.items():
                  ^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'items'
2023-11-19 17:08:36,269 [INFO]: package: mysql.connector.plugins
2023-11-19 17:08:36,269 [INFO]: plugin_name: caching_sha2_password
2023-11-19 17:08:36,272 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 17:20:45,824 [ERROR]: An error occurred: '>' not supported between instances of 'dict' and 'int'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 69, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs > 1 else None
                                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: '>' not supported between instances of 'dict' and 'int'
2023-11-19 17:25:15,842 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x558dd84675e3 <unknown>
#1 0x558dd812a0b7 <unknown>
#2 0x558dd8177f53 <unknown>
#3 0x558dd8178051 <unknown>
#4 0x558dd81bd9c4 <unknown>
#5 0x558dd819ef1d <unknown>
#6 0x558dd81bab3d <unknown>
#7 0x558dd819ecc3 <unknown>
#8 0x558dd816a0e4 <unknown>
#9 0x558dd816b0ae <unknown>
#10 0x558dd842dce1 <unknown>
#11 0x558dd8431b7e <unknown>
#12 0x558dd841b4b5 <unknown>
#13 0x558dd84327d6 <unknown>
#14 0x558dd83fedbf <unknown>
#15 0x558dd8455748 <unknown>
#16 0x558dd8455917 <unknown>
#17 0x558dd8466773 <unknown>
#18 0x7f5bbde64ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 54, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x558dd84675e3 <unknown>
#1 0x558dd812a0b7 <unknown>
#2 0x558dd8177f53 <unknown>
#3 0x558dd8178051 <unknown>
#4 0x558dd81bd9c4 <unknown>
#5 0x558dd819ef1d <unknown>
#6 0x558dd81bab3d <unknown>
#7 0x558dd819ecc3 <unknown>
#8 0x558dd816a0e4 <unknown>
#9 0x558dd816b0ae <unknown>
#10 0x558dd842dce1 <unknown>
#11 0x558dd8431b7e <unknown>
#12 0x558dd841b4b5 <unknown>
#13 0x558dd84327d6 <unknown>
#14 0x558dd83fedbf <unknown>
#15 0x558dd8455748 <unknown>
#16 0x558dd8455917 <unknown>
#17 0x558dd8466773 <unknown>
#18 0x7f5bbde64ac3 <unknown>

2023-11-19 17:26:58,623 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x5602ed37b5e3 <unknown>
#1 0x5602ed03e0b7 <unknown>
#2 0x5602ed08bf53 <unknown>
#3 0x5602ed08c051 <unknown>
#4 0x5602ed0d19c4 <unknown>
#5 0x5602ed0b2f1d <unknown>
#6 0x5602ed0ceb3d <unknown>
#7 0x5602ed0b2cc3 <unknown>
#8 0x5602ed07e0e4 <unknown>
#9 0x5602ed07f0ae <unknown>
#10 0x5602ed341ce1 <unknown>
#11 0x5602ed345b7e <unknown>
#12 0x5602ed32f4b5 <unknown>
#13 0x5602ed3467d6 <unknown>
#14 0x5602ed312dbf <unknown>
#15 0x5602ed369748 <unknown>
#16 0x5602ed369917 <unknown>
#17 0x5602ed37a773 <unknown>
#18 0x7f8e23f1aac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x5602ed37b5e3 <unknown>
#1 0x5602ed03e0b7 <unknown>
#2 0x5602ed08bf53 <unknown>
#3 0x5602ed08c051 <unknown>
#4 0x5602ed0d19c4 <unknown>
#5 0x5602ed0b2f1d <unknown>
#6 0x5602ed0ceb3d <unknown>
#7 0x5602ed0b2cc3 <unknown>
#8 0x5602ed07e0e4 <unknown>
#9 0x5602ed07f0ae <unknown>
#10 0x5602ed341ce1 <unknown>
#11 0x5602ed345b7e <unknown>
#12 0x5602ed32f4b5 <unknown>
#13 0x5602ed3467d6 <unknown>
#14 0x5602ed312dbf <unknown>
#15 0x5602ed369748 <unknown>
#16 0x5602ed369917 <unknown>
#17 0x5602ed37a773 <unknown>
#18 0x7f8e23f1aac3 <unknown>

2023-11-19 17:28:56,925 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x56308621a5e3 <unknown>
#1 0x563085edd0b7 <unknown>
#2 0x563085f2af53 <unknown>
#3 0x563085f2b051 <unknown>
#4 0x563085f709c4 <unknown>
#5 0x563085f51f1d <unknown>
#6 0x563085f6db3d <unknown>
#7 0x563085f51cc3 <unknown>
#8 0x563085f1d0e4 <unknown>
#9 0x563085f1e0ae <unknown>
#10 0x5630861e0ce1 <unknown>
#11 0x5630861e4b7e <unknown>
#12 0x5630861ce4b5 <unknown>
#13 0x5630861e57d6 <unknown>
#14 0x5630861b1dbf <unknown>
#15 0x563086208748 <unknown>
#16 0x563086208917 <unknown>
#17 0x563086219773 <unknown>
#18 0x7fe893fa8ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x56308621a5e3 <unknown>
#1 0x563085edd0b7 <unknown>
#2 0x563085f2af53 <unknown>
#3 0x563085f2b051 <unknown>
#4 0x563085f709c4 <unknown>
#5 0x563085f51f1d <unknown>
#6 0x563085f6db3d <unknown>
#7 0x563085f51cc3 <unknown>
#8 0x563085f1d0e4 <unknown>
#9 0x563085f1e0ae <unknown>
#10 0x5630861e0ce1 <unknown>
#11 0x5630861e4b7e <unknown>
#12 0x5630861ce4b5 <unknown>
#13 0x5630861e57d6 <unknown>
#14 0x5630861b1dbf <unknown>
#15 0x563086208748 <unknown>
#16 0x563086208917 <unknown>
#17 0x563086219773 <unknown>
#18 0x7fe893fa8ac3 <unknown>

2023-11-19 17:30:50,165 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x562f62dd95e3 <unknown>
#1 0x562f62a9c0b7 <unknown>
#2 0x562f62ae9f53 <unknown>
#3 0x562f62aea051 <unknown>
#4 0x562f62b2f9c4 <unknown>
#5 0x562f62b10f1d <unknown>
#6 0x562f62b2cb3d <unknown>
#7 0x562f62b10cc3 <unknown>
#8 0x562f62adc0e4 <unknown>
#9 0x562f62add0ae <unknown>
#10 0x562f62d9fce1 <unknown>
#11 0x562f62da3b7e <unknown>
#12 0x562f62d8d4b5 <unknown>
#13 0x562f62da47d6 <unknown>
#14 0x562f62d70dbf <unknown>
#15 0x562f62dc7748 <unknown>
#16 0x562f62dc7917 <unknown>
#17 0x562f62dd8773 <unknown>
#18 0x7f993c85eac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x562f62dd95e3 <unknown>
#1 0x562f62a9c0b7 <unknown>
#2 0x562f62ae9f53 <unknown>
#3 0x562f62aea051 <unknown>
#4 0x562f62b2f9c4 <unknown>
#5 0x562f62b10f1d <unknown>
#6 0x562f62b2cb3d <unknown>
#7 0x562f62b10cc3 <unknown>
#8 0x562f62adc0e4 <unknown>
#9 0x562f62add0ae <unknown>
#10 0x562f62d9fce1 <unknown>
#11 0x562f62da3b7e <unknown>
#12 0x562f62d8d4b5 <unknown>
#13 0x562f62da47d6 <unknown>
#14 0x562f62d70dbf <unknown>
#15 0x562f62dc7748 <unknown>
#16 0x562f62dc7917 <unknown>
#17 0x562f62dd8773 <unknown>
#18 0x7f993c85eac3 <unknown>

2023-11-19 17:31:21,677 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x55b9e3c655e3 <unknown>
#1 0x55b9e39280b7 <unknown>
#2 0x55b9e3975f53 <unknown>
#3 0x55b9e3976051 <unknown>
#4 0x55b9e39bb9c4 <unknown>
#5 0x55b9e399cf1d <unknown>
#6 0x55b9e39b8b3d <unknown>
#7 0x55b9e399ccc3 <unknown>
#8 0x55b9e39680e4 <unknown>
#9 0x55b9e39690ae <unknown>
#10 0x55b9e3c2bce1 <unknown>
#11 0x55b9e3c2fb7e <unknown>
#12 0x55b9e3c194b5 <unknown>
#13 0x55b9e3c307d6 <unknown>
#14 0x55b9e3bfcdbf <unknown>
#15 0x55b9e3c53748 <unknown>
#16 0x55b9e3c53917 <unknown>
#17 0x55b9e3c64773 <unknown>
#18 0x7f4517f11ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x55b9e3c655e3 <unknown>
#1 0x55b9e39280b7 <unknown>
#2 0x55b9e3975f53 <unknown>
#3 0x55b9e3976051 <unknown>
#4 0x55b9e39bb9c4 <unknown>
#5 0x55b9e399cf1d <unknown>
#6 0x55b9e39b8b3d <unknown>
#7 0x55b9e399ccc3 <unknown>
#8 0x55b9e39680e4 <unknown>
#9 0x55b9e39690ae <unknown>
#10 0x55b9e3c2bce1 <unknown>
#11 0x55b9e3c2fb7e <unknown>
#12 0x55b9e3c194b5 <unknown>
#13 0x55b9e3c307d6 <unknown>
#14 0x55b9e3bfcdbf <unknown>
#15 0x55b9e3c53748 <unknown>
#16 0x55b9e3c53917 <unknown>
#17 0x55b9e3c64773 <unknown>
#18 0x7f4517f11ac3 <unknown>

2023-11-19 17:40:10,267 [ERROR]: An error occurred: module 'selenium.webdriver.support.expected_conditions' has no attribute 'visibility_of_of_element_located'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    WebDriverWait(self.br,5).until(EC.visibility_of_of_element_located((By.NAME,"wpforms[fields][1][first]")))
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'selenium.webdriver.support.expected_conditions' has no attribute 'visibility_of_of_element_located'. Did you mean: 'visibility_of_element_located'?
2023-11-19 18:05:17,754 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 119, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 18:08:41,946 [INFO]: package: mysql.connector.plugins
2023-11-19 18:08:41,947 [INFO]: plugin_name: caching_sha2_password
2023-11-19 18:08:41,954 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 19:01:52,142 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    db_handler.store_data(batch_results)
  File "/root/projects/corey/src/scraping/scraper1.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 19:57:28,649 [INFO]: package: mysql.connector.plugins
2023-11-19 19:57:28,650 [INFO]: plugin_name: caching_sha2_password
2023-11-19 19:57:28,653 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 19:58:36,944 [INFO]: package: mysql.connector.plugins
2023-11-19 19:58:36,945 [INFO]: plugin_name: caching_sha2_password
2023-11-19 19:58:36,946 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 20:00:28,182 [ERROR]: An error occurred: HTTPSConnectionPool(host='mobilendloan.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc4c95ce7b0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -3] Temporary failure in name resolution

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 1058, in _validate_conn
    conn.connect()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fc4c95ce7b0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='mobilendloan.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc4c95ce7b0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 39, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='mobilendloan.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc4c95ce7b0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))
2023-11-19 20:03:12,634 [INFO]: package: mysql.connector.plugins
2023-11-19 20:03:12,634 [INFO]: plugin_name: caching_sha2_password
2023-11-19 20:03:12,636 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 20:55:19,952 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 21:00:58,330 [INFO]: package: mysql.connector.plugins
2023-11-19 21:00:58,331 [INFO]: plugin_name: caching_sha2_password
2023-11-19 21:00:58,334 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-19 21:59:09,098 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    data = {'refCode':refcode}
             ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    last_name_el = soup.select_one("#lastName")['value'] if soup.select_one("#lastName") else None
                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 22:12:24,534 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 23:12:32,245 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-20 23:02:21,229 [INFO]: package: mysql.connector.plugins
2023-11-20 23:02:21,230 [INFO]: plugin_name: caching_sha2_password
2023-11-20 23:02:21,232 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-20 23:49:17,836 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-20 23:51:25,732 [INFO]: package: mysql.connector.plugins
2023-11-20 23:51:25,733 [INFO]: plugin_name: caching_sha2_password
2023-11-20 23:51:25,740 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-20 23:51:28,969 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-20 23:51:51,878 [INFO]: package: mysql.connector.plugins
2023-11-20 23:51:51,879 [INFO]: plugin_name: caching_sha2_password
2023-11-20 23:51:51,888 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-20 23:51:55,230 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 124, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-20 23:53:58,955 [INFO]: package: mysql.connector.plugins
2023-11-20 23:53:58,956 [INFO]: plugin_name: caching_sha2_password
2023-11-20 23:53:58,959 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 00:52:26,252 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 00:52:26,263 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 00:59:50,539 [INFO]: package: mysql.connector.plugins
2023-11-21 00:59:50,540 [INFO]: plugin_name: caching_sha2_password
2023-11-21 00:59:50,546 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 00:59:53,824 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 01:00:39,446 [INFO]: package: mysql.connector.plugins
2023-11-21 01:00:39,447 [INFO]: plugin_name: caching_sha2_password
2023-11-21 01:00:39,449 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 01:00:42,724 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 01:02:10,594 [INFO]: package: mysql.connector.plugins
2023-11-21 01:02:10,594 [INFO]: plugin_name: caching_sha2_password
2023-11-21 01:02:10,597 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 01:31:29,501 [INFO]: Scraping and storing data completed successfully.
2023-11-21 02:01:00,644 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
    time.sleep(0.3)
             ^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    last_name_el = soup.select_one("#lastName")['value'] if soup.select_one("#lastName") else None
                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 02:01:00,791 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 124, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 02:05:25,978 [INFO]: package: mysql.connector.plugins
2023-11-21 02:05:25,980 [INFO]: plugin_name: caching_sha2_password
2023-11-21 02:05:25,986 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 02:11:15,094 [INFO]: Scraping and storing data completed successfully.
2023-11-21 03:03:25,988 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
    for batch_results in scraper1.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 03:03:26,542 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 03:08:45,523 [INFO]: package: mysql.connector.plugins
2023-11-21 03:08:45,524 [INFO]: plugin_name: caching_sha2_password
2023-11-21 03:08:45,524 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 03:20:57,938 [INFO]: Scraping and storing data completed successfully.
2023-11-21 04:05:10,000 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 27, in main
  File "/root/projects/corey/src/scraping/scraper1.py", line 120, in scrape_with_refcodes
    data = {'refCode':refcode}
             ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    first_name_el = soup.select_one("#firstName")['value'] if soup.select_one("#firstName") else None
                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 04:05:10,658 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    # Store data in the db
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    time.sleep(0.3)
             ^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    last_name_el = soup.select_one("#lastName")['value'] if soup.select_one("#lastName") else None
                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 04:08:13,795 [INFO]: package: mysql.connector.plugins
2023-11-21 04:08:13,796 [INFO]: plugin_name: caching_sha2_password
2023-11-21 04:08:13,798 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 04:08:32,454 [INFO]: package: mysql.connector.plugins
2023-11-21 04:08:32,455 [INFO]: plugin_name: caching_sha2_password
2023-11-21 04:08:32,456 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 04:09:37,509 [INFO]: package: mysql.connector.plugins
2023-11-21 04:09:37,509 [INFO]: plugin_name: caching_sha2_password
2023-11-21 04:09:37,510 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 05:06:29,025 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 05:23:54,408 [INFO]: package: mysql.connector.plugins
2023-11-21 05:23:54,410 [INFO]: plugin_name: caching_sha2_password
2023-11-21 05:23:54,413 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 06:22:00,537 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-21 23:02:14,751 [INFO]: package: mysql.connector.plugins
2023-11-21 23:02:14,757 [INFO]: plugin_name: caching_sha2_password
2023-11-21 23:02:14,759 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-21 23:37:54,846 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
TypeError: 'NoneType' object is not subscriptable
2023-11-22 00:04:18,455 [ERROR]: An error occurred: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 971, in json
    return complexjson.loads(self.text, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 16, in get_proxies
    proxies = response.json()
              ^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 975, in json
    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)
requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2023-11-22 00:06:44,158 [ERROR]: An error occurred: name 'respose' is not defined
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 16, in get_proxies
    print(respose.content)
          ^^^^^^^
NameError: name 'respose' is not defined. Did you mean: 'response'?
2023-11-22 00:07:11,962 [ERROR]: An error occurred: Expecting value: line 1 column 1 (char 0)
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 971, in json
    return complexjson.loads(self.text, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 17, in get_proxies
    proxies = response.json()
              ^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 975, in json
    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)
requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2023-11-22 00:12:16,178 [INFO]: package: mysql.connector.plugins
2023-11-22 00:12:16,179 [INFO]: plugin_name: caching_sha2_password
2023-11-22 00:12:16,180 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 00:51:34,294 [INFO]: package: mysql.connector.plugins
2023-11-22 00:51:34,295 [INFO]: plugin_name: caching_sha2_password
2023-11-22 00:51:34,298 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 00:53:01,977 [INFO]: package: mysql.connector.plugins
2023-11-22 00:53:01,978 [INFO]: plugin_name: caching_sha2_password
2023-11-22 00:53:01,984 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 01:02:20,624 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 01:06:56,188 [INFO]: package: mysql.connector.plugins
2023-11-22 01:06:56,190 [INFO]: plugin_name: caching_sha2_password
2023-11-22 01:06:56,193 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 02:05:16,068 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 124, in scrape_with_refcodes
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 02:07:04,682 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 20, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:07:57,229 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 20, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:09:18,012 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 20, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:09:47,862 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 21, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:10:32,928 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 21, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:10:56,066 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 21, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:11:33,112 [ERROR]: An error occurred: byte indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 17, in main
    scraper = Scraper1()
      ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 9, in __init__
    self.proxies = self.get_proxies()
                   ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 22, in get_proxies
    return [{'http': f'http://{proxy["ip"]}:{proxy["port"]}', 'https': f'https://{proxy["ip"]}:{proxy["port"]}'} for proxy in proxies]
                               ~~~~~^^^^^^
TypeError: byte indices must be integers or slices, not str
2023-11-22 02:12:20,348 [INFO]: package: mysql.connector.plugins
2023-11-22 02:12:20,348 [INFO]: plugin_name: caching_sha2_password
2023-11-22 02:12:20,349 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 02:12:22,142 [ERROR]: An error occurred: generate_code() missing 1 required positional argument: 'prefix'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 106, in scrape_with_refcodes
    refcodes = code_generator.generate_code(51274,222000)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_code() missing 1 required positional argument: 'prefix'
2023-11-22 02:14:50,637 [INFO]: package: mysql.connector.plugins
2023-11-22 02:14:50,637 [INFO]: plugin_name: caching_sha2_password
2023-11-22 02:14:50,638 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 02:14:52,442 [ERROR]: An error occurred: generate_code() missing 1 required positional argument: 'prefix'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_wproxy.py", line 105, in scrape_with_refcodes
    refcodes = code_generator.generate_code(51274,222000)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_code() missing 1 required positional argument: 'prefix'
2023-11-22 02:15:07,682 [INFO]: package: mysql.connector.plugins
2023-11-22 02:15:07,682 [INFO]: plugin_name: caching_sha2_password
2023-11-22 02:15:07,683 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 02:19:30,825 [INFO]: package: mysql.connector.plugins
2023-11-22 02:19:30,825 [INFO]: plugin_name: caching_sha2_password
2023-11-22 02:19:30,826 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:15:02,713 [ERROR]: An error occurred: 2055: Lost connection to MySQL server at '45.77.98.126:3306', system error: 104 Connection reset by peer
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 233, in recv
    header = self._recv_chunk(sock, size=PACKET_HEADER_LENGTH)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 178, in _recv_chunk
    read = sock.recv_into(pkt_view, size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/pooling.py", line 294, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 169, in __init__
    self.connect(**kwargs)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 1217, in connect
    self._open_connection()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 578, in _open_connection
    self._do_handshake()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 198, in _do_handshake
    packet = self._socket.recv()
             ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 614, in recv
    return self._netbroker.recv(self.sock, self.address)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 244, in recv
    raise OperationalError(
mysql.connector.errors.OperationalError: 2055: Lost connection to MySQL server at '45.77.98.126:3306', system error: 104 Connection reset by peer
2023-11-22 03:16:55,204 [INFO]: package: mysql.connector.plugins
2023-11-22 03:16:55,205 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:16:55,211 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:16:55,212 [INFO]: package: mysql.connector.plugins
2023-11-22 03:16:55,212 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:16:55,213 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:17:00,720 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 108, in scrape_with_refcodes
    batch_results = list(executor.map(scrape_single_thread,refcodes[i:i+batch_size]))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:21:25,733 [INFO]: package: mysql.connector.plugins
2023-11-22 03:21:25,734 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:21:25,735 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:21:25,735 [INFO]: package: mysql.connector.plugins
2023-11-22 03:21:25,735 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:21:25,736 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:21:31,111 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 108, in scrape_with_refcodes
    batch_results = list(executor.map(scrape_single_thread,refcodes[i:i+batch_size]))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:36:15,019 [INFO]: package: mysql.connector.plugins
2023-11-22 03:36:15,020 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:36:15,021 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:36:15,021 [INFO]: package: mysql.connector.plugins
2023-11-22 03:36:15,021 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:36:15,022 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:36:17,933 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 108, in scrape_with_refcodes
    batch_results = list(executor.map(scrape_single_thread,refcodes[i:i+batch_size]))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:37:36,027 [INFO]: package: mysql.connector.plugins
2023-11-22 03:37:36,028 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:37:36,028 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:37:36,029 [INFO]: package: mysql.connector.plugins
2023-11-22 03:37:36,029 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:37:36,029 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:37:38,977 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 108, in scrape_with_refcodes
    batch_results = list(executor.map(scrape_single_thread,refcodes[i:i+batch_size]))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:38:40,194 [INFO]: package: mysql.connector.plugins
2023-11-22 03:38:40,195 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:38:40,196 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:38:44,898 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 108, in scrape_with_refcodes
    batch_results = list(executor.map(scrape_single_thread,refcodes[i:i+batch_size]))
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 54, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:38:56,649 [INFO]: package: mysql.connector.plugins
2023-11-22 03:38:56,649 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:38:56,649 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:38:59,937 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:41:13,147 [ERROR]: An error occurred: 2055: Lost connection to MySQL server at '45.77.98.126:3306', system error: 104 Connection reset by peer
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 233, in recv
    header = self._recv_chunk(sock, size=PACKET_HEADER_LENGTH)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 178, in _recv_chunk
    read = sock.recv_into(pkt_view, size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/pooling.py", line 294, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 169, in __init__
    self.connect(**kwargs)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 1217, in connect
    self._open_connection()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 578, in _open_connection
    self._do_handshake()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 198, in _do_handshake
    packet = self._socket.recv()
             ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 614, in recv
    return self._netbroker.recv(self.sock, self.address)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 244, in recv
    raise OperationalError(
mysql.connector.errors.OperationalError: 2055: Lost connection to MySQL server at '45.77.98.126:3306', system error: 104 Connection reset by peer
2023-11-22 03:41:40,215 [INFO]: package: mysql.connector.plugins
2023-11-22 03:41:40,215 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:41:40,216 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:41:40,216 [INFO]: package: mysql.connector.plugins
2023-11-22 03:41:40,216 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:41:40,217 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:42:00,943 [INFO]: package: mysql.connector.plugins
2023-11-22 03:42:00,943 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:42:00,944 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:42:00,944 [INFO]: package: mysql.connector.plugins
2023-11-22 03:42:00,944 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:42:00,945 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:42:32,406 [INFO]: package: mysql.connector.plugins
2023-11-22 03:42:32,406 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:42:32,406 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:42:32,407 [INFO]: package: mysql.connector.plugins
2023-11-22 03:42:32,407 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:42:32,408 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:43:10,241 [ERROR]: An error occurred: DatabaseHandler.store_data() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 37, in main
    db_handler.store_data(scraper.table_name,batch_results)
TypeError: DatabaseHandler.store_data() takes 2 positional arguments but 3 were given
2023-11-22 03:46:08,099 [INFO]: package: mysql.connector.plugins
2023-11-22 03:46:08,099 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:46:08,100 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:46:08,100 [INFO]: package: mysql.connector.plugins
2023-11-22 03:46:08,101 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:46:08,101 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:46:42,510 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 37, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/root/projects/corey/src/database/database_handler_local.py", line 38, in store_data
    ''', (data['first_name'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:48:16,328 [INFO]: package: mysql.connector.plugins
2023-11-22 03:48:16,329 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:48:16,329 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:48:16,330 [INFO]: package: mysql.connector.plugins
2023-11-22 03:48:16,330 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:48:16,331 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:48:51,992 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 37, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/root/projects/corey/src/database/database_handler_local.py", line 38, in store_data
    ''', (data['first_name'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 03:50:08,938 [INFO]: package: mysql.connector.plugins
2023-11-22 03:50:08,939 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:50:08,939 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:50:08,940 [INFO]: package: mysql.connector.plugins
2023-11-22 03:50:08,940 [INFO]: plugin_name: mysql_native_password
2023-11-22 03:50:08,940 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 03:53:44,266 [ERROR]: An error occurred: DatabaseHandler.__init__() missing 1 required positional argument: 'table_names'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
TypeError: DatabaseHandler.__init__() missing 1 required positional argument: 'table_names'
2023-11-22 03:54:01,983 [ERROR]: An error occurred: DatabaseHandler.__init__() missing 1 required positional argument: 'table_names'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
TypeError: DatabaseHandler.__init__() missing 1 required positional argument: 'table_names'
2023-11-22 03:54:24,463 [ERROR]: An error occurred: DatabaseHandler.__init__() missing 1 required positional argument: 'table_names'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
TypeError: DatabaseHandler.__init__() missing 1 required positional argument: 'table_names'
2023-11-22 03:56:00,960 [ERROR]: An error occurred: 2055: Lost connection to MySQL server at '45.77.98.126:3306', system error: 104 Connection reset by peer
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 233, in recv
    header = self._recv_chunk(sock, size=PACKET_HEADER_LENGTH)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 178, in _recv_chunk
    read = sock.recv_into(pkt_view, size)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 20, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/pooling.py", line 294, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 169, in __init__
    self.connect(**kwargs)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 1217, in connect
    self._open_connection()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 578, in _open_connection
    self._do_handshake()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 198, in _do_handshake
    packet = self._socket.recv()
             ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 614, in recv
    return self._netbroker.recv(self.sock, self.address)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/network.py", line 244, in recv
    raise OperationalError(
mysql.connector.errors.OperationalError: 2055: Lost connection to MySQL server at '45.77.98.126:3306', system error: 104 Connection reset by peer
2023-11-22 03:57:21,329 [INFO]: package: mysql.connector.plugins
2023-11-22 03:57:21,330 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:57:21,332 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 03:59:24,040 [INFO]: package: mysql.connector.plugins
2023-11-22 03:59:24,040 [INFO]: plugin_name: caching_sha2_password
2023-11-22 03:59:24,041 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 04:09:32,001 [INFO]: package: mysql.connector.plugins
2023-11-22 04:09:32,002 [INFO]: plugin_name: caching_sha2_password
2023-11-22 04:09:32,003 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 04:34:10,525 [INFO]: package: mysql.connector.plugins
2023-11-22 04:34:10,526 [INFO]: plugin_name: caching_sha2_password
2023-11-22 04:34:10,530 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 04:35:06,247 [INFO]: package: mysql.connector.plugins
2023-11-22 04:35:06,248 [INFO]: plugin_name: caching_sha2_password
2023-11-22 04:35:06,251 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 04:39:17,925 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 116, in scrape_with_refcodes
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 105, in scrape_single_thread
    else:
          
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 62, in scrape_single
    state_el = None
                    
TypeError: 'NoneType' object is not subscriptable
2023-11-22 04:43:28,362 [INFO]: package: mysql.connector.plugins
2023-11-22 04:43:28,363 [INFO]: plugin_name: caching_sha2_password
2023-11-22 04:43:28,364 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 05:41:35,553 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 112, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 58, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 05:44:51,335 [INFO]: package: mysql.connector.plugins
2023-11-22 05:44:51,336 [INFO]: plugin_name: caching_sha2_password
2023-11-22 05:44:51,336 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 16:19:39,466 [INFO]: package: mysql.connector.plugins
2023-11-22 16:19:39,467 [INFO]: plugin_name: caching_sha2_password
2023-11-22 16:19:39,470 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 16:19:39,472 [INFO]: package: mysql.connector.plugins
2023-11-22 16:19:39,472 [INFO]: plugin_name: mysql_native_password
2023-11-22 16:19:39,484 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 16:19:42,689 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 111, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 100, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 57, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-22 23:59:28,510 [INFO]: package: mysql.connector.plugins
2023-11-22 23:59:28,510 [INFO]: plugin_name: caching_sha2_password
2023-11-22 23:59:28,511 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-22 23:59:28,511 [INFO]: package: mysql.connector.plugins
2023-11-22 23:59:28,512 [INFO]: plugin_name: mysql_native_password
2023-11-22 23:59:28,512 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-22 23:59:28,525 [ERROR]: An error occurred: 'Scraper3' object has no attribute 'generate_code'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper3.py", line 82, in scrape_with_refcodes
    refcodes = self.generate_code(8,20000,'RD')
               ^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper3' object has no attribute 'generate_code'
2023-11-23 00:00:04,008 [INFO]: package: mysql.connector.plugins
2023-11-23 00:00:04,008 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:00:04,009 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:00:04,010 [INFO]: package: mysql.connector.plugins
2023-11-23 00:00:04,010 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:00:04,010 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:00:06,691 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper3.py", line 99, in scrape_with_refcodes
    batch_results = [result for result in executor.map(scrape_single_thread,refcodes[i:i+batch_size]) if result is not None ]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    for script in scripts:
TypeError: 'NoneType' object is not iterable
2023-11-23 00:02:13,939 [INFO]: package: mysql.connector.plugins
2023-11-23 00:02:13,939 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:02:13,939 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:02:13,940 [INFO]: package: mysql.connector.plugins
2023-11-23 00:02:13,940 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:02:13,940 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:02:15,003 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    for script in scripts:
TypeError: 'NoneType' object is not iterable
2023-11-23 00:03:09,279 [INFO]: package: mysql.connector.plugins
2023-11-23 00:03:09,280 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:03:09,280 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:03:09,281 [INFO]: package: mysql.connector.plugins
2023-11-23 00:03:09,281 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:03:09,281 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:03:10,346 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 99, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 90, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    for script in scripts:
TypeError: 'NoneType' object is not iterable
2023-11-23 00:06:09,541 [INFO]: package: mysql.connector.plugins
2023-11-23 00:06:09,541 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:06:09,542 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:06:09,542 [INFO]: package: mysql.connector.plugins
2023-11-23 00:06:09,542 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:06:09,543 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:06:10,712 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    for script in scripts:
TypeError: 'NoneType' object is not iterable
2023-11-23 00:06:50,718 [INFO]: package: mysql.connector.plugins
2023-11-23 00:06:50,719 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:06:50,719 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:06:50,720 [INFO]: package: mysql.connector.plugins
2023-11-23 00:06:50,720 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:06:50,721 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:06:51,863 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    for script in scripts:
TypeError: 'NoneType' object is not iterable
2023-11-23 00:09:58,026 [INFO]: package: mysql.connector.plugins
2023-11-23 00:09:58,027 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:09:58,027 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:09:58,028 [INFO]: package: mysql.connector.plugins
2023-11-23 00:09:58,028 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:09:58,029 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:09:59,147 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    for script in scripts:
TypeError: 'NoneType' object is not iterable
2023-11-23 00:13:16,507 [INFO]: package: mysql.connector.plugins
2023-11-23 00:13:16,507 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:13:16,508 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:13:16,509 [INFO]: package: mysql.connector.plugins
2023-11-23 00:13:16,509 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:13:16,510 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:13:21,347 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:15:07,254 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:17:23,345 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:18:00,745 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:18:11,660 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:30:50,566 [INFO]: package: mysql.connector.plugins
2023-11-23 00:30:50,566 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:30:50,567 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:30:50,567 [INFO]: package: mysql.connector.plugins
2023-11-23 00:30:50,568 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:30:50,568 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:30:52,279 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 112, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 58, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-23 00:30:57,097 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 112, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 58, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-23 00:31:17,679 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 112, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 58, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-23 00:42:53,646 [INFO]: package: mysql.connector.plugins
2023-11-23 00:42:53,646 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:42:53,647 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:42:53,650 [INFO]: package: mysql.connector.plugins
2023-11-23 00:42:53,650 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:42:53,651 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:42:55,334 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 112, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 58, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-23 00:43:03,583 [INFO]: package: mysql.connector.plugins
2023-11-23 00:43:03,584 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:43:03,584 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:43:03,585 [INFO]: package: mysql.connector.plugins
2023-11-23 00:43:03,585 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:43:03,585 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:43:07,676 [ERROR]: An error occurred: Invalid URL '/': No scheme supplied. Perhaps you meant https:///?
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 106, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 56, in scrape_single
    resubmit_response = requests.post(action, headers=headers, data=data, allow_redirects=True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL '/': No scheme supplied. Perhaps you meant https:///?
2023-11-23 00:44:05,802 [INFO]: package: mysql.connector.plugins
2023-11-23 00:44:05,803 [INFO]: plugin_name: caching_sha2_password
2023-11-23 00:44:05,804 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 00:44:05,804 [INFO]: package: mysql.connector.plugins
2023-11-23 00:44:05,805 [INFO]: plugin_name: mysql_native_password
2023-11-23 00:44:05,805 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-23 00:44:09,396 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 106, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 67, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:44:30,096 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 106, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 67, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:45:20,516 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 106, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 97, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 67, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 00:58:21,750 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 97, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 88, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 58, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 01:02:48,230 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 98, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 01:07:36,020 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 101, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 92, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 62, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 01:11:15,806 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 110, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 71, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 01:46:11,286 [ERROR]: An error occurred: cannot use a string pattern on a bytes-like object
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 122, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    match = re.search(pattern,js_code)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/re/__init__.py", line 177, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cannot use a string pattern on a bytes-like object
2023-11-23 01:46:34,503 [ERROR]: An error occurred: cannot use a string pattern on a bytes-like object
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 123, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    match = re.search(pattern,js_code)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/re/__init__.py", line 177, in search
    return _compile(pattern, flags).search(string)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cannot use a string pattern on a bytes-like object
2023-11-23 01:50:43,030 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 85, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 01:52:12,137 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 85, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 01:57:01,328 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 116, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 86, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:10:00,194 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 116, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 86, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:13:54,549 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 126, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 87, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:14:40,770 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 126, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 87, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:16:36,845 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 128, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 119, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:17:03,435 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 128, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 119, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:20:48,242 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 128, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 119, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:23:24,878 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 128, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 119, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:25:30,156 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 128, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 119, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 89, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:25:56,034 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 129, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 90, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:28:53,327 [ERROR]: An error occurred: name 'response' is not defined
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 130, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    print(response.headers)
          ^^^^^^^^
NameError: name 'response' is not defined
2023-11-23 02:29:08,556 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 130, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 91, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:29:42,355 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 130, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 91, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 02:46:53,150 [ERROR]: An error occurred: name 'url' is not defined
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper = Scraper()
              ^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 11, in __init__
    print(f'{url}?RefCode={data['refCode']}')
             ^^^
NameError: name 'url' is not defined
2023-11-23 03:05:14,118 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 134, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 95, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:05:37,634 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 134, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 95, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:07:02,970 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 135, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 126, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 96, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:08:44,055 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 135, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 126, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 96, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:18:08,774 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 94, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:18:48,541 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 94, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:19:20,104 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 94, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:19:38,192 [ERROR]: An error occurred: name 'source_valu' is not defined
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    print(source_valu/e)
          ^^^^^^^^^^^
NameError: name 'source_valu' is not defined. Did you mean: 'source_value'?
2023-11-23 03:19:47,651 [ERROR]: An error occurred: name 'source_valu' is not defined
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 59, in scrape_single
    print(source_valu/e)
          ^^^^^^^^^^^
NameError: name 'source_valu' is not defined. Did you mean: 'source_value'?
2023-11-23 03:20:02,376 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 133, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 124, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 94, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:23:11,327 [ERROR]: An error occurred: 'NoneType' object has no attribute 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 135, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 126, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 96, in scrape_single
    zip_code_el = soup.find(attrs={"name":"wpforms[fields][4][postal]"})['value'] if 'value' in soup.find(attrs={"name":"wpforms[fields][4][postal]"}).attrs else None
                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'attrs'
2023-11-23 03:41:04,583 [ERROR]: An error occurred: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/venv/corey/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/root/venv/corey/lib/python3.12/site-packages/urllib3/connectionpool.py", line 462, in _make_request
    httplib_response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 1411, in getresponse
    response.begin()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 324, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/http/client.py", line 293, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 135, in scrape_with_refcodes
    scrape_single_thread(code)
  File "/root/projects/corey/src/scraping/scraper3.py", line 126, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    response = session.post(f'{url}?RefCode={data['refCode']}',headers=headers,allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/requests/adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2023-11-23 03:47:06,846 [ERROR]: An error occurred: 'Scraper4' object has no attribute 'scrape_with_refcodes'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scrape_with_refcodes():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper4' object has no attribute 'scrape_with_refcodes'
2023-11-23 03:48:02,006 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scraped_with_names():
TypeError: 'NoneType' object is not iterable
2023-11-23 03:48:26,998 [ERROR]: An error occurred: 'First Name'
Traceback (most recent call last):
  File "/root/venv/corey/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3790, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'First Name'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scraped_with_names():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 77, in scraped_with_names
    names = self.generate_names()
            ^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 110, in generate_names
    first_names = df_first_names['First Name'].tolist()
                  ~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/pandas/core/frame.py", line 3893, in __getitem__
    indexer = self.columns.get_loc(key)
              ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3797, in get_loc
    raise KeyError(key) from err
KeyError: 'First Name'
2023-11-23 03:51:14,474 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scraped_with_names():
TypeError: 'NoneType' object is not iterable
2023-11-23 03:51:50,472 [ERROR]: An error occurred: 'NoneType' object is not iterable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scraped_with_names():
TypeError: 'NoneType' object is not iterable
2023-11-23 06:21:18,643 [ERROR]: An error occurred: generate_names() missing 1 required positional argument: 'self'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scraped_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 78, in scraped_with_names
    names = name_generator.generate_names()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: generate_names() missing 1 required positional argument: 'self'
2023-11-23 06:22:12,651 [INFO]: package: mysql.connector.plugins
2023-11-23 06:22:12,651 [INFO]: plugin_name: caching_sha2_password
2023-11-23 06:22:12,652 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-23 06:22:16,141 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    for batch_results in scraper.scrape_with_refcodes():
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 112, in scrape_with_refcodes
    batch_results = [result for result in list(executor.map(scrape_single_thread,refcodes[i:i+batch_size])) if result is not None]
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 619, in result_iterator
    yield _result_or_cancel(fs.pop())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 317, in _result_or_cancel
    return fut.result(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 101, in scrape_single_thread
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1_threading.py", line 58, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-23 06:22:53,434 [ERROR]: An error occurred: cannot access local variable 'name' where it is not associated with a value
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper.scraped_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 79, in scraped_with_names
    print(f"There {len(name)} names to rotate!")
                       ^^^^
UnboundLocalError: cannot access local variable 'name' where it is not associated with a value
2023-11-23 06:27:20,957 [ERROR]: An error occurred: name 'Scraper' is not defined
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 19, in main
    scraper = Scraper()
              ^^^^^^^
NameError: name 'Scraper' is not defined. Did you mean: 'Scraperpip'?
2023-11-23 06:27:41,728 [ERROR]: An error occurred: cannot access local variable 'name' where it is not associated with a value
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scraped_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 79, in scraped_with_names
    print(f"There {len(name)} names to rotate!")
                       ^^^^
UnboundLocalError: cannot access local variable 'name' where it is not associated with a value
2023-11-24 02:57:13,800 [INFO]: package: mysql.connector.plugins
2023-11-24 02:57:13,804 [INFO]: plugin_name: caching_sha2_password
2023-11-24 02:57:13,807 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 02:57:13,813 [INFO]: package: mysql.connector.plugins
2023-11-24 02:57:13,813 [INFO]: plugin_name: mysql_native_password
2023-11-24 02:57:13,817 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 02:57:13,959 [ERROR]: An error occurred: 'Scraper4' object has no attribute 'scraped_with_names'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scraped_with_names():
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Scraper4' object has no attribute 'scraped_with_names'. Did you mean: 'scrape_with_names'?
2023-11-24 02:57:45,258 [INFO]: package: mysql.connector.plugins
2023-11-24 02:57:45,259 [INFO]: plugin_name: caching_sha2_password
2023-11-24 02:57:45,259 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 02:57:45,260 [INFO]: package: mysql.connector.plugins
2023-11-24 02:57:45,260 [INFO]: plugin_name: mysql_native_password
2023-11-24 02:57:45,260 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 02:57:45,844 [ERROR]: An error occurred: cannot access local variable 'name' where it is not associated with a value
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 73, in scrape_with_names
    print(f"There {len(name)} names to rotate!")
                       ^^^^
UnboundLocalError: cannot access local variable 'name' where it is not associated with a value
2023-11-24 02:58:04,405 [INFO]: package: mysql.connector.plugins
2023-11-24 02:58:04,405 [INFO]: plugin_name: caching_sha2_password
2023-11-24 02:58:04,406 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 02:58:04,408 [INFO]: package: mysql.connector.plugins
2023-11-24 02:58:04,409 [INFO]: plugin_name: mysql_native_password
2023-11-24 02:58:04,409 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 02:58:06,998 [ERROR]: An error occurred: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //('James',%20'SMITH')1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3f105764b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 1058, in _validate_conn
    conn.connect()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f3f105764b0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //('James',%20'SMITH')1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3f105764b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 85, in scrape_with_names
    result = executor.submit(scrape_single_with_increment,name,count).result()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 78, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 36, in scrape_single
    response = requests.post(f"https://{url}", headers=headers, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //('James',%20'SMITH')1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3f105764b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
2023-11-24 03:01:58,218 [INFO]: package: mysql.connector.plugins
2023-11-24 03:01:58,219 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:01:58,219 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:01:58,220 [INFO]: package: mysql.connector.plugins
2023-11-24 03:01:58,220 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:01:58,220 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:04:47,651 [INFO]: package: mysql.connector.plugins
2023-11-24 03:04:47,651 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:04:47,652 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:04:47,652 [INFO]: package: mysql.connector.plugins
2023-11-24 03:04:47,653 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:04:47,653 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:04:48,155 [ERROR]: An error occurred: object of type 'generator' has no len()
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 73, in scrape_with_names
    print(f"There {len(names)} names to rotate!")
                   ^^^^^^^^^^
TypeError: object of type 'generator' has no len()
2023-11-24 03:05:35,782 [INFO]: package: mysql.connector.plugins
2023-11-24 03:05:35,783 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:05:35,784 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:05:35,784 [INFO]: package: mysql.connector.plugins
2023-11-24 03:05:35,784 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:05:35,785 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:05:36,387 [ERROR]: An error occurred: str.join() takes exactly one argument (2 given)
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 72, in scrape_with_names
    names = name_generator.generate_names()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/name_generator.py", line 23, in generate_names
    all_name_combinations = [''.join(pair[0],pair[1]).lower() for pair in list(product(first_names[start_index:],last_names))]
                             ^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: str.join() takes exactly one argument (2 given)
2023-11-24 03:06:55,096 [INFO]: package: mysql.connector.plugins
2023-11-24 03:06:55,096 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:06:55,097 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:06:55,098 [INFO]: package: mysql.connector.plugins
2023-11-24 03:06:55,098 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:06:55,098 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:08:01,735 [INFO]: package: mysql.connector.plugins
2023-11-24 03:08:01,736 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:08:01,736 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:08:01,737 [INFO]: package: mysql.connector.plugins
2023-11-24 03:08:01,737 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:08:01,738 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:08:04,489 [ERROR]: An error occurred: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe6ccfe28a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 1058, in _validate_conn
    conn.connect()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fe6ccfe28a0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe6ccfe28a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 85, in scrape_with_names
    result = executor.submit(scrape_single_with_increment,name,count).result()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 78, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 36, in scrape_single
    response = requests.post(f"https://{url}", headers=headers, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fe6ccfe28a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
2023-11-24 03:09:02,906 [INFO]: package: mysql.connector.plugins
2023-11-24 03:09:02,906 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:09:02,907 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:09:02,907 [INFO]: package: mysql.connector.plugins
2023-11-24 03:09:02,907 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:09:02,908 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:09:05,745 [ERROR]: An error occurred: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fed4122a7b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 1058, in _validate_conn
    conn.connect()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fed4122a7b0>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fed4122a7b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 86, in scrape_with_names
    result = executor.submit(scrape_single_with_increment,name,count).result()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 79, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 36, in scrape_single
    response = requests.post(f"https://{url}", headers=headers, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fed4122a7b0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
2023-11-24 03:12:32,063 [INFO]: package: mysql.connector.plugins
2023-11-24 03:12:32,063 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:12:32,064 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:12:32,064 [INFO]: package: mysql.connector.plugins
2023-11-24 03:12:32,065 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:12:32,065 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:12:32,745 [ERROR]: An error occurred: Header part (('purl_visitor=eyJpdiI6IllTR1hab0ZITHAxTm9sM2JpOW5aQ1E9PSIsInZhbHVlIjoieHRXTVFsUldZMDBBSmQzYmxrYTdyYUVBeUJvbEErTE8rK25kaE0vS2g1ZGhacU1pWU10WXU5VVFiMEJxUzNRVDdOSnhIUVdqWWV3eHFWVy8xZXJ2dmwyZ0J3dVdkR1VLNEpJdnM5OGJsWWtJeElMTEpyNkhObnhUWkxoWDcwUXVpaXh0UFNNZGtUclpxUTVZblVXQ3RUNExZMmkxaEtsS1pqZnZuWDczL25nPSIsIm1hYyI6IjQ2ZDE4MDExY2U1ZWRjOWMyNTJjYTZmZDRjYTU3OTYwYzdhOWQxMDMyMWMyZWNiMWRiMzNjNjdjYWMzNzFiYTUiLCJ0YWciOiIifQ%3D%3D; leadid_token-8AB3EFE0-1097-22B0-3825-76FA271DC046-E3C5F1E1-D995-07DC-7419-327C3CD5CF3F=D1F0C806-930D-F2B3-291B-AA23499108C7',)) from ('Cookie', ('purl_visitor=eyJpdiI6IllTR1hab0ZITHAxTm9sM2JpOW5aQ1E9PSIsInZhbHVlIjoieHRXTVFsUldZMDBBSmQzYmxrYTdyYUVBeUJvbEErTE8rK25kaE0vS2g1ZGhacU1pWU10WXU5VVFiMEJxUzNRVDdOSnhIUVdqWWV3eHFWVy8xZXJ2dmwyZ0J3dVdkR1VLNEpJdnM5OGJsWWtJeElMTEpyNkhObnhUWkxoWDcwUXVpaXh0UFNNZGtUclpxUTVZblVXQ3RUNExZMmkxaEtsS1pqZnZuWDczL25nPSIsIm1hYyI6IjQ2ZDE4MDExY2U1ZWRjOWMyNTJjYTZmZDRjYTU3OTYwYzdhOWQxMDMyMWMyZWNiMWRiMzNjNjdjYWMzNzFiYTUiLCJ0YWciOiIifQ%3D%3D; leadid_token-8AB3EFE0-1097-22B0-3825-76FA271DC046-E3C5F1E1-D995-07DC-7419-327C3CD5CF3F=D1F0C806-930D-F2B3-291B-AA23499108C7',)) must be of type str or bytes, not <class 'tuple'>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 88, in scrape_with_names
    result = executor.submit(scrape_single_with_increment,name,count).result()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 38, in scrape_single
    response = requests.post(f"https://{url}", headers=headers, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1040, in check_header_validity
    _validate_header_part(header, value, 1)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1049, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Header part (('purl_visitor=eyJpdiI6IllTR1hab0ZITHAxTm9sM2JpOW5aQ1E9PSIsInZhbHVlIjoieHRXTVFsUldZMDBBSmQzYmxrYTdyYUVBeUJvbEErTE8rK25kaE0vS2g1ZGhacU1pWU10WXU5VVFiMEJxUzNRVDdOSnhIUVdqWWV3eHFWVy8xZXJ2dmwyZ0J3dVdkR1VLNEpJdnM5OGJsWWtJeElMTEpyNkhObnhUWkxoWDcwUXVpaXh0UFNNZGtUclpxUTVZblVXQ3RUNExZMmkxaEtsS1pqZnZuWDczL25nPSIsIm1hYyI6IjQ2ZDE4MDExY2U1ZWRjOWMyNTJjYTZmZDRjYTU3OTYwYzdhOWQxMDMyMWMyZWNiMWRiMzNjNjdjYWMzNzFiYTUiLCJ0YWciOiIifQ%3D%3D; leadid_token-8AB3EFE0-1097-22B0-3825-76FA271DC046-E3C5F1E1-D995-07DC-7419-327C3CD5CF3F=D1F0C806-930D-F2B3-291B-AA23499108C7',)) from ('Cookie', ('purl_visitor=eyJpdiI6IllTR1hab0ZITHAxTm9sM2JpOW5aQ1E9PSIsInZhbHVlIjoieHRXTVFsUldZMDBBSmQzYmxrYTdyYUVBeUJvbEErTE8rK25kaE0vS2g1ZGhacU1pWU10WXU5VVFiMEJxUzNRVDdOSnhIUVdqWWV3eHFWVy8xZXJ2dmwyZ0J3dVdkR1VLNEpJdnM5OGJsWWtJeElMTEpyNkhObnhUWkxoWDcwUXVpaXh0UFNNZGtUclpxUTVZblVXQ3RUNExZMmkxaEtsS1pqZnZuWDczL25nPSIsIm1hYyI6IjQ2ZDE4MDExY2U1ZWRjOWMyNTJjYTZmZDRjYTU3OTYwYzdhOWQxMDMyMWMyZWNiMWRiMzNjNjdjYWMzNzFiYTUiLCJ0YWciOiIifQ%3D%3D; leadid_token-8AB3EFE0-1097-22B0-3825-76FA271DC046-E3C5F1E1-D995-07DC-7419-327C3CD5CF3F=D1F0C806-930D-F2B3-291B-AA23499108C7',)) must be of type str or bytes, not <class 'tuple'>
2023-11-24 03:16:44,502 [INFO]: package: mysql.connector.plugins
2023-11-24 03:16:44,503 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:16:44,503 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:16:44,504 [INFO]: package: mysql.connector.plugins
2023-11-24 03:16:44,504 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:16:44,505 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:16:47,293 [ERROR]: An error occurred: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc52d553140>: Failed to establish a new connection: [Errno -2] Name or service not known'))
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/socket.py", line 963, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 715, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 404, in _make_request
    self._validate_conn(conn)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 1058, in _validate_conn
    conn.connect()
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7fc52d553140>: Failed to establish a new connection: [Errno -2] Name or service not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc52d553140>: Failed to establish a new connection: [Errno -2] Name or service not known'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 88, in scrape_with_names
    result = executor.submit(scrape_single_with_increment,name,count).result()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 456, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 38, in scrape_single
    response = requests.post(f"https://{url}", headers=headers, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='https', port=443): Max retries exceeded with url: //jamessmith1.moneyladdernow.com (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fc52d553140>: Failed to establish a new connection: [Errno -2] Name or service not known'))
2023-11-24 03:19:15,373 [INFO]: package: mysql.connector.plugins
2023-11-24 03:19:15,374 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:19:15,374 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:19:15,375 [INFO]: package: mysql.connector.plugins
2023-11-24 03:19:15,375 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:19:15,375 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:20:23,425 [INFO]: package: mysql.connector.plugins
2023-11-24 03:20:23,425 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:20:23,426 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:20:23,426 [INFO]: package: mysql.connector.plugins
2023-11-24 03:20:23,426 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:20:23,427 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:37:44,794 [INFO]: package: mysql.connector.plugins
2023-11-24 03:37:44,794 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:37:44,795 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:37:44,795 [INFO]: package: mysql.connector.plugins
2023-11-24 03:37:44,796 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:37:44,796 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:38:41,231 [INFO]: package: mysql.connector.plugins
2023-11-24 03:38:41,231 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:38:41,232 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:38:41,232 [INFO]: package: mysql.connector.plugins
2023-11-24 03:38:41,232 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:38:41,233 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:40:56,410 [INFO]: package: mysql.connector.plugins
2023-11-24 03:40:56,411 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:40:56,411 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:40:56,412 [INFO]: package: mysql.connector.plugins
2023-11-24 03:40:56,412 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:40:56,413 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:41:53,442 [INFO]: package: mysql.connector.plugins
2023-11-24 03:41:53,443 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:41:53,444 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:41:53,444 [INFO]: package: mysql.connector.plugins
2023-11-24 03:41:53,444 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:41:53,445 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:45:06,783 [INFO]: package: mysql.connector.plugins
2023-11-24 03:45:06,784 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:45:06,784 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:45:06,785 [INFO]: package: mysql.connector.plugins
2023-11-24 03:45:06,785 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:45:06,786 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:45:19,525 [INFO]: package: mysql.connector.plugins
2023-11-24 03:45:19,525 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:45:19,526 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:45:19,527 [INFO]: package: mysql.connector.plugins
2023-11-24 03:45:19,527 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:45:19,527 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:50:34,244 [INFO]: package: mysql.connector.plugins
2023-11-24 03:50:34,245 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:50:34,246 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:50:34,246 [INFO]: package: mysql.connector.plugins
2023-11-24 03:50:34,246 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:50:34,247 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:50:35,977 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 88, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 80, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 50, in scrape_single
    state_el = soup.select("#state")[1].text if soup.select("#state") else 'NA'
               ~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-24 03:51:03,978 [INFO]: package: mysql.connector.plugins
2023-11-24 03:51:03,979 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:51:03,980 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:51:03,980 [INFO]: package: mysql.connector.plugins
2023-11-24 03:51:03,980 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:51:03,981 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 03:51:26,741 [INFO]: package: mysql.connector.plugins
2023-11-24 03:51:26,741 [INFO]: plugin_name: caching_sha2_password
2023-11-24 03:51:26,742 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 03:51:26,743 [INFO]: package: mysql.connector.plugins
2023-11-24 03:51:26,743 [INFO]: plugin_name: mysql_native_password
2023-11-24 03:51:26,745 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:03:43,406 [INFO]: package: mysql.connector.plugins
2023-11-24 04:03:43,407 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:03:43,408 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:03:43,408 [INFO]: package: mysql.connector.plugins
2023-11-24 04:03:43,408 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:03:43,409 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:04:24,078 [INFO]: package: mysql.connector.plugins
2023-11-24 04:04:24,078 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:04:24,079 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:04:24,079 [INFO]: package: mysql.connector.plugins
2023-11-24 04:04:24,079 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:04:24,080 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:04:25,814 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 88, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 80, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 50, in scrape_single
    state_el = soup.select("#state option:checked")[1].text if soup.select("#state") else 'NA'
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-24 04:13:13,447 [INFO]: package: mysql.connector.plugins
2023-11-24 04:13:13,448 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:13:13,448 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:13:13,449 [INFO]: package: mysql.connector.plugins
2023-11-24 04:13:13,449 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:13:13,450 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:13:15,400 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 89, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 50, in scrape_single
    state_el = soup.select("#state option:checked")[1].text if soup.select("#state") else 'NA'
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-24 04:13:50,779 [INFO]: package: mysql.connector.plugins
2023-11-24 04:13:50,780 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:13:50,780 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:13:50,781 [INFO]: package: mysql.connector.plugins
2023-11-24 04:13:50,781 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:13:50,782 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:13:52,470 [ERROR]: An error occurred: ResultSet object has no attribute 'decode_contents'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 89, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 50, in scrape_single
    print(soup.select("#state").decode_contents())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 2428, in __getattr__
    raise AttributeError(
AttributeError: ResultSet object has no attribute 'decode_contents'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
2023-11-24 04:14:43,312 [INFO]: package: mysql.connector.plugins
2023-11-24 04:14:43,312 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:14:43,313 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:14:43,314 [INFO]: package: mysql.connector.plugins
2023-11-24 04:14:43,314 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:14:43,314 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:14:45,065 [ERROR]: An error occurred: 'NoneType' object has no attribute 'decode_contents'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 89, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 50, in scrape_single
    print(soup.find("#state").decode_contents())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'decode_contents'
2023-11-24 04:17:02,001 [INFO]: package: mysql.connector.plugins
2023-11-24 04:17:02,001 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:17:02,002 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:17:02,003 [INFO]: package: mysql.connector.plugins
2023-11-24 04:17:02,003 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:17:02,003 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:17:03,776 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 89, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 51, in scrape_single
    state_el = soup.select("#state option:checked")[1].text if soup.select("#state") else 'NA'
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-24 04:29:48,605 [INFO]: package: mysql.connector.plugins
2023-11-24 04:29:48,607 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:29:48,607 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:29:48,608 [INFO]: package: mysql.connector.plugins
2023-11-24 04:29:48,608 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:29:48,609 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:29:50,423 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 34, in main
    for batch_results in scraper.scrape_with_names():
  File "/root/projects/corey/src/scraping/scraper4.py", line 89, in scrape_with_names
    result = scrape_single_with_increment(name,count)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 81, in scrape_single_with_increment
    result = self.scrape_single(base_url)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper4.py", line 51, in scrape_single
    state_el = soup.select("#state option:checked")[1].text if soup.select("#state") else 'NA'
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-24 04:55:33,901 [INFO]: package: mysql.connector.plugins
2023-11-24 04:55:33,901 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:55:33,902 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:55:33,904 [INFO]: package: mysql.connector.plugins
2023-11-24 04:55:33,904 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:55:33,904 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:56:00,551 [ERROR]: An error occurred: 1146 (42S02): Table 'scraped_data.scraper4_info' doesn't exist
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 38, in main
    db_handler.store_data(scraper.table_name,batch_results)
  File "/root/projects/corey/src/database/database_handler_local.py", line 35, in store_data
    self.cursor.execute(f'''
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/cursor.py", line 617, in execute
    self._handle_result(self._connection.cmd_query(stmt))
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 1069, in cmd_query
    result = self._handle_result(self._send_cmd(ServerCmd.QUERY, query))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 846, in _handle_result
    raise get_exception(packet)
mysql.connector.errors.ProgrammingError: 1146 (42S02): Table 'scraped_data.scraper4_info' doesn't exist
2023-11-24 04:57:13,609 [INFO]: package: mysql.connector.plugins
2023-11-24 04:57:13,609 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:57:13,610 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:57:13,611 [INFO]: package: mysql.connector.plugins
2023-11-24 04:57:13,611 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:57:13,612 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 04:59:34,918 [INFO]: package: mysql.connector.plugins
2023-11-24 04:59:34,919 [INFO]: plugin_name: caching_sha2_password
2023-11-24 04:59:34,919 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 04:59:34,920 [INFO]: package: mysql.connector.plugins
2023-11-24 04:59:34,920 [INFO]: plugin_name: mysql_native_password
2023-11-24 04:59:34,921 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 05:07:15,039 [INFO]: package: mysql.connector.plugins
2023-11-24 05:07:15,039 [INFO]: plugin_name: caching_sha2_password
2023-11-24 05:07:15,040 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 05:07:15,040 [INFO]: package: mysql.connector.plugins
2023-11-24 05:07:15,040 [INFO]: plugin_name: mysql_native_password
2023-11-24 05:07:15,041 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-24 05:08:17,872 [INFO]: package: mysql.connector.plugins
2023-11-24 05:08:17,872 [INFO]: plugin_name: caching_sha2_password
2023-11-24 05:08:17,873 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-24 05:08:17,874 [INFO]: package: mysql.connector.plugins
2023-11-24 05:08:17,874 [INFO]: plugin_name: mysql_native_password
2023-11-24 05:08:17,874 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
