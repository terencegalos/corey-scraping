2023-11-15 17:23:29,975 [ERROR]: An error occurred: [Errno 2] No such file or directory: 'refcodes.txt'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 68, in scrape_with_refcodes
    with open(refcodes_file,'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'refcodes.txt'
2023-11-15 17:24:08,961 [ERROR]: An error occurred: 'Scraper1' object has no attribute 'url'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
                                ^^^^^^^^
AttributeError: 'Scraper1' object has no attribute 'url'
2023-11-15 17:24:38,086 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:24:59,862 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:30:50,656 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:41:01,449 [ERROR]: An error occurred: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 106, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    first_name = first_name_el.text.strip()
                 ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 2428, in __getattr__
    raise AttributeError(
AttributeError: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
2023-11-15 17:47:19,951 [INFO]: package: mysql.connector.plugins
2023-11-15 17:47:19,951 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:47:19,952 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:47:19,954 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AUTOINCREMENT,
                                first_name VARCHAR(255),
        ' at line 2
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 28, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 16, in __init__
    self.cursor.execute('''
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/cursor.py", line 617, in execute
    self._handle_result(self._connection.cmd_query(stmt))
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 1069, in cmd_query
    result = self._handle_result(self._send_cmd(ServerCmd.QUERY, query))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 846, in _handle_result
    raise get_exception(packet)
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AUTOINCREMENT,
                                first_name VARCHAR(255),
        ' at line 2
2023-11-15 17:49:13,074 [INFO]: package: mysql.connector.plugins
2023-11-15 17:49:13,075 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:49:13,076 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:49:13,109 [ERROR]: An error occurred: 'firstname'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 37, in main
    db_handler.store_data(data1)
  File "/root/projects/corey/src/database/database_handler.py", line 38, in store_data
    ''', (data['firstname'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^
KeyError: 'firstname'
2023-11-15 17:50:13,096 [INFO]: package: mysql.connector.plugins
2023-11-15 17:50:13,096 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:50:13,097 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:50:13,111 [INFO]: Scraping and storing data completed successfully.
2023-11-15 17:51:05,400 [INFO]: package: mysql.connector.plugins
2023-11-15 17:51:05,401 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:51:05,401 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:51:05,414 [INFO]: Scraping and storing data completed successfully.
2023-11-15 17:59:32,010 [INFO]: package: mysql.connector.plugins
2023-11-15 17:59:32,011 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:59:32,011 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:59:32,024 [INFO]: Scraping and storing data completed successfully.
2023-11-15 18:38:21,721 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:38:43,037 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:41:36,095 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:42:55,182 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:45:05,663 [INFO]: Scraping and storing data completed successfully.
2023-11-15 19:05:35,285 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper2.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-15 19:18:14,921 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 24, in main
    data1 = scraper3.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:08:33,995 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 106, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 43, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:09:23,556 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:25:10,553 [INFO]: package: mysql.connector.plugins
2023-11-16 08:25:10,554 [INFO]: plugin_name: caching_sha2_password
2023-11-16 08:25:10,555 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 08:25:10,556 [INFO]: package: mysql.connector.plugins
2023-11-16 08:25:10,556 [INFO]: plugin_name: mysql_native_password
2023-11-16 08:25:10,556 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 08:25:10,580 [INFO]: Scraping and storing data completed successfully.
2023-11-16 09:17:36,515 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 44, in scrape_single
    first_name_el = soup.select("#firstName")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 09:29:03,882 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    first_name_el = soup.select("#firstName")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 09:40:28,653 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 35, in scrape_single
    csrf_token = soup.find('meta',{'name':'csrf-token'})['content']
                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 09:43:06,185 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 126, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 63, in scrape_single
    first_name_el = soup.select_one("#firstName")['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 10:05:00,405 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:06:21,463 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:08:38,495 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:14:16,485 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:14:24,397 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:15:02,047 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:16:18,216 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:17:25,488 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    state_el = soup.select_one("#state")['value']
               ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-16 10:20:20,948 [ERROR]: An error occurred: 'str' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    first_name = first_name_el.text.strip()
                 ^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'text'
2023-11-16 10:21:37,887 [INFO]: package: mysql.connector.plugins
2023-11-16 10:21:37,887 [INFO]: plugin_name: caching_sha2_password
2023-11-16 10:21:37,887 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 10:21:37,888 [INFO]: package: mysql.connector.plugins
2023-11-16 10:21:37,888 [INFO]: plugin_name: mysql_native_password
2023-11-16 10:21:37,888 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 10:21:37,903 [INFO]: Scraping and storing data completed successfully.
2023-11-16 10:25:06,304 [ERROR]: An error occurred: 1
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    state_el = soup.select_one("#state option[selected]")[1].text
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 1
2023-11-16 10:30:58,571 [INFO]: package: mysql.connector.plugins
2023-11-16 10:30:58,571 [INFO]: plugin_name: caching_sha2_password
2023-11-16 10:30:58,572 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 10:30:58,572 [INFO]: package: mysql.connector.plugins
2023-11-16 10:30:58,573 [INFO]: plugin_name: mysql_native_password
2023-11-16 10:30:58,573 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 10:30:58,583 [INFO]: Scraping and storing data completed successfully.
2023-11-16 15:22:02,532 [INFO]: package: mysql.connector.plugins
2023-11-16 15:22:02,533 [INFO]: plugin_name: caching_sha2_password
2023-11-16 15:22:02,533 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 15:22:02,534 [INFO]: package: mysql.connector.plugins
2023-11-16 15:22:02,534 [INFO]: plugin_name: mysql_native_password
2023-11-16 15:22:02,534 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 15:22:02,547 [INFO]: Scraping and storing data completed successfully.
2023-11-16 16:22:41,568 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 46, in scrape_single
    first_name_el = soup.select_one("#firstName")['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:23:11,993 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:23:31,118 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:32:41,969 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:34:59,917 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:43:37,734 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 110, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 44, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:56:05,608 [ERROR]: An error occurred: 'Response' object has no attribute 'header'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    redirect_url = response.header['Location']
                   ^^^^^^^^^^^^^^^
AttributeError: 'Response' object has no attribute 'header'. Did you mean: 'headers'?
2023-11-16 16:56:28,219 [ERROR]: An error occurred: 'location'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    redirect_url = response.headers['Location']
                   ~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/structures.py", line 52, in __getitem__
    return self._store[key.lower()][1]
           ~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'location'
2023-11-16 16:57:11,265 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 46, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:58:18,626 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 46, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:04:17,928 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:05:03,972 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:20:48,915 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 116, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:21:24,353 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:27:40,451 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:29:10,556 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 48, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:31:25,821 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 48, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:41:34,966 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 52, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:56:45,530 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:57:05,786 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:08:22,932 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:09:11,792 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:10:45,775 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:12:03,399 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:24:37,965 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:25:28,105 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:25:59,854 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:41:52,482 [INFO]: Starting Chromium download.
2023-11-16 20:42:23,637 [INFO]: Beginning extraction
2023-11-16 20:42:25,489 [INFO]: Chromium extracted to: /root/.local/share/pyppeteer/local-chromium/588429
2023-11-16 20:42:25,800 [INFO]: Browser listening on: ws://127.0.0.1:43131/devtools/browser/a9d855d5-19f9-435d-ad9d-5b06ce3280f3
2023-11-16 20:42:30,009 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:42:30,011 [INFO]: terminate chrome process...
2023-11-16 20:45:04,780 [INFO]: Browser listening on: ws://127.0.0.1:43375/devtools/browser/a64d8c9c-fdab-4dd4-84c2-896fbaf26c63
2023-11-16 20:45:10,945 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:45:10,947 [INFO]: terminate chrome process...
2023-11-16 20:48:38,029 [INFO]: Browser listening on: ws://127.0.0.1:46737/devtools/browser/065861ec-5d42-4327-bb47-d9b9b1002074
2023-11-16 20:48:41,964 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 49, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 20:48:41,966 [INFO]: terminate chrome process...
2023-11-16 21:10:20,904 [INFO]: Browser listening on: ws://127.0.0.1:58309/devtools/browser/ad398b31-18a5-473f-a5fb-b7eb43abf104
2023-11-16 21:10:24,886 [ERROR]: An error occurred: 'list' object has no attribute 'find'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input=[name="wpforms[fields][1]"]',first=True).attrs['value'] = data['refCode']
    ^^^^^^^^^
AttributeError: 'list' object has no attribute 'find'
2023-11-16 21:10:24,889 [INFO]: terminate chrome process...
2023-11-16 21:12:57,184 [INFO]: Browser listening on: ws://127.0.0.1:52593/devtools/browser/4455ea81-8f7f-4113-840c-4af9b71af0ba
2023-11-16 21:13:01,965 [ERROR]: An error occurred: 'list' object has no attribute 'find'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input=[name="wpforms[fields][1]"]',first=True).attrs['value'] = data['refCode']
    ^^^^^^^^^
AttributeError: 'list' object has no attribute 'find'
2023-11-16 21:13:01,966 [INFO]: terminate chrome process...
2023-11-16 21:14:10,225 [INFO]: Browser listening on: ws://127.0.0.1:33365/devtools/browser/2b599bdf-14aa-457d-8ab3-4d0eb78f62dd
2023-11-16 21:14:13,868 [ERROR]: An error occurred: Expected selector, got <DELIM '=' at 5>
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input=[name="wpforms[fields][1]"]',first=True).attrs['value'] = data['refCode']
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests_html.py", line 212, in find
    for found in self.pq(selector)
                 ^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 256, in __call__
    result = self._copy(*args, parent=self, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 242, in _copy
    return self.__class__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 227, in __init__
    xpath = self._css_to_xpath(selector)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 238, in _css_to_xpath
    return self._translator.css_to_xpath(selector, prefix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/xpath.py", line 224, in css_to_xpath
    for selector in parse(css)
                    ^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 543, in parse
    return list(parse_selector_group(stream))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 558, in parse_selector_group
    yield Selector(*parse_selector(stream))
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 567, in parse_selector
    result, pseudo_element = parse_simple_selector(stream)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 700, in parse_simple_selector
    raise SelectorSyntaxError("Expected selector, got %s" % (peek,))
cssselect.parser.SelectorSyntaxError: Expected selector, got <DELIM '=' at 5>
2023-11-16 21:14:13,871 [INFO]: terminate chrome process...
2023-11-16 21:16:47,049 [INFO]: Browser listening on: ws://127.0.0.1:49713/devtools/browser/059dc3c0-4d46-4fb8-959c-ba39cfec2870
2023-11-16 21:16:50,447 [ERROR]: An error occurred: 'Element' object has no attribute 'submit'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 41, in scrape_single
    response = form.submit()
               ^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'submit'
2023-11-16 21:16:50,450 [INFO]: terminate chrome process...
2023-11-16 21:24:02,257 [INFO]: Browser listening on: ws://127.0.0.1:41945/devtools/browser/f884f73d-f256-4b79-873a-a962b76546c9
2023-11-16 21:24:06,316 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    e.attrs['name'] : e.attrs['value'] for e in form.find('input')
                      ~~~~~~~^^^^^^^^^
KeyError: 'value'
2023-11-16 21:24:06,317 [INFO]: terminate chrome process...
2023-11-16 21:27:01,379 [INFO]: Browser listening on: ws://127.0.0.1:47361/devtools/browser/a95721c1-7edb-4a60-b366-fe22f675bfe9
2023-11-16 21:27:05,841 [ERROR]: An error occurred: Invalid URL '/': No scheme supplied. Perhaps you meant https:///?
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    response = session.post(post_url)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 368, in prepare
    self.prepare_url(url, params)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 439, in prepare_url
    raise MissingSchema(
requests.exceptions.MissingSchema: Invalid URL '/': No scheme supplied. Perhaps you meant https:///?
2023-11-16 21:27:05,844 [INFO]: terminate chrome process...
2023-11-16 21:28:08,068 [INFO]: Browser listening on: ws://127.0.0.1:39659/devtools/browser/dd222181-ab5a-48d7-b97a-0e7d0c72aded
2023-11-16 21:28:13,342 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 21:28:13,344 [INFO]: terminate chrome process...
2023-11-16 21:28:46,368 [INFO]: Browser listening on: ws://127.0.0.1:55173/devtools/browser/742bae92-b46b-47e2-a126-426d289cf920
2023-11-16 21:28:50,814 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 21:28:50,816 [INFO]: terminate chrome process...
2023-11-16 21:29:54,586 [INFO]: Browser listening on: ws://127.0.0.1:34707/devtools/browser/a9ed0081-50a9-4e0e-accc-e5de85f5384d
2023-11-16 21:29:59,337 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 55, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 21:29:59,339 [INFO]: terminate chrome process...
2023-11-16 21:34:09,444 [INFO]: Browser listening on: ws://127.0.0.1:46921/devtools/browser/1a17da75-bcba-40cb-9660-79afb008fb3c
2023-11-16 21:34:12,928 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'wpforms[fields][1]':data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:34:12,930 [INFO]: terminate chrome process...
2023-11-16 21:36:15,433 [INFO]: Browser listening on: ws://127.0.0.1:35847/devtools/browser/52df5a1d-6b37-460f-b506-d20435269bfb
2023-11-16 21:36:19,519 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'wpforms[fields][1]':data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:36:19,522 [INFO]: terminate chrome process...
2023-11-16 21:38:36,370 [INFO]: Browser listening on: ws://127.0.0.1:52297/devtools/browser/0b7764f2-fe0f-4ca1-a407-e0ed9ce0caa3
2023-11-16 21:38:39,661 [ERROR]: An error occurred: 'Element' object has no attribute 'form'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 38, in scrape_single
    form = response.html.find('#wpforms-form-4251', first=True).form
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'form'
2023-11-16 21:38:39,662 [INFO]: terminate chrome process...
2023-11-16 21:43:58,235 [INFO]: Browser listening on: ws://127.0.0.1:44459/devtools/browser/b7bf8e31-b1d9-4e34-8727-17e3fe7eb14f
2023-11-16 21:44:02,186 [ERROR]: An error occurred: BaseParser.find() got an unexpected keyword argument 'attrs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find(attrs={'name':'wpforms[fields][1]'})['value'] = data['refCode']
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: BaseParser.find() got an unexpected keyword argument 'attrs'
2023-11-16 21:44:02,188 [INFO]: terminate chrome process...
2023-11-16 21:44:47,469 [INFO]: Browser listening on: ws://127.0.0.1:39835/devtools/browser/b9358fe7-6c4e-4331-b00c-99c243925a90
2023-11-16 21:44:51,027 [ERROR]: An error occurred: Expected ']', got <EOF at 31>
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input[name="wpforms[fields][1]"')['value'] = data['refCode']
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests_html.py", line 212, in find
    for found in self.pq(selector)
                 ^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 256, in __call__
    result = self._copy(*args, parent=self, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 242, in _copy
    return self.__class__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 227, in __init__
    xpath = self._css_to_xpath(selector)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pyquery/pyquery.py", line 238, in _css_to_xpath
    return self._translator.css_to_xpath(selector, prefix)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/xpath.py", line 224, in css_to_xpath
    for selector in parse(css)
                    ^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 543, in parse
    return list(parse_selector_group(stream))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 558, in parse_selector_group
    yield Selector(*parse_selector(stream))
                    ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 567, in parse_selector
    result, pseudo_element = parse_simple_selector(stream)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 634, in parse_simple_selector
    result = parse_attrib(result, stream)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/cssselect/parser.py", line 802, in parse_attrib
    raise SelectorSyntaxError("Expected ']', got %s" % (next,))
cssselect.parser.SelectorSyntaxError: Expected ']', got <EOF at 31>
2023-11-16 21:44:51,030 [INFO]: terminate chrome process...
2023-11-16 21:46:46,368 [INFO]: Browser listening on: ws://127.0.0.1:39231/devtools/browser/25167be1-c4c1-4263-8789-e21e66e34554
2023-11-16 21:46:49,704 [ERROR]: An error occurred: list indices must be integers or slices, not str
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.find('input[name="wpforms[fields][1]"]')['value'] = data['refCode']
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: list indices must be integers or slices, not str
2023-11-16 21:46:49,706 [INFO]: terminate chrome process...
2023-11-16 21:47:39,731 [INFO]: Browser listening on: ws://127.0.0.1:42159/devtools/browser/6d4780ff-544b-44ce-9a9f-fca5202c7411
2023-11-16 21:47:43,271 [ERROR]: An error occurred: 'Element' object has no attribute 'submit'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    response = form.submit()
               ^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'submit'
2023-11-16 21:47:43,279 [INFO]: terminate chrome process...
2023-11-16 21:50:13,971 [INFO]: Browser listening on: ws://127.0.0.1:48893/devtools/browser/dab3472e-419d-49f8-8915-4f8ef1f29c3c
2023-11-16 21:50:18,022 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'input[name="wpforms[fields][1]"]':data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:50:18,024 [INFO]: terminate chrome process...
2023-11-16 21:56:09,119 [INFO]: Browser listening on: ws://127.0.0.1:43535/devtools/browser/980dd5e1-7e61-4df6-97ef-6c38ccf87354
2023-11-16 21:56:12,641 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:56:12,643 [INFO]: terminate chrome process...
2023-11-16 21:57:56,028 [INFO]: Browser listening on: ws://127.0.0.1:56633/devtools/browser/cda93083-a21e-4ff4-a08d-d34e200922bf
2023-11-16 21:57:59,432 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 40, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:57:59,434 [INFO]: terminate chrome process...
2023-11-16 21:58:21,114 [INFO]: Browser listening on: ws://127.0.0.1:58709/devtools/browser/bb969dc2-f084-47c4-b176-0f80e6207cf6
2023-11-16 21:58:25,219 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 40, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 21:58:25,221 [INFO]: terminate chrome process...
2023-11-16 22:00:50,569 [INFO]: Browser listening on: ws://127.0.0.1:41955/devtools/browser/006738c1-3f8a-449d-82f3-22e0ab32ceb9
2023-11-16 22:00:54,621 [ERROR]: An error occurred: 'Element' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 40, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'input'
2023-11-16 22:00:54,623 [INFO]: terminate chrome process...
2023-11-16 22:06:23,424 [INFO]: Browser listening on: ws://127.0.0.1:43367/devtools/browser/25c7f503-9f30-47d8-a868-39e4ade55fe7
2023-11-16 22:06:27,060 [ERROR]: An error occurred: 'FormElement' object has no attribute 'input'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 41, in scrape_single
    form.input({'wpforms[fields][1]': data['refCode']})
    ^^^^^^^^^^
AttributeError: 'FormElement' object has no attribute 'input'. Did you mean: 'inputs'?
2023-11-16 22:06:27,065 [INFO]: terminate chrome process...
2023-11-16 22:09:40,493 [INFO]: Browser listening on: ws://127.0.0.1:40237/devtools/browser/557a630c-276a-4ae3-917e-6240b06cec5d
2023-11-16 22:09:43,931 [ERROR]: An error occurred: 'Element' object has no attribute 'inputs'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    inputs = form_el.inputs
             ^^^^^^^^^^^^^^
AttributeError: 'Element' object has no attribute 'inputs'
2023-11-16 22:09:43,934 [INFO]: terminate chrome process...
2023-11-17 15:55:03,544 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 54, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-17 16:17:37,123 [ERROR]: An error occurred: 2003 (HY000): Can't connect to MySQL server on '103.40.3.37:3306' (110)
Traceback (most recent call last):
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 308, in _open_connection
    self._cmysql.connect(**cnx_kwargs)
_mysql_connector.MySQLInterfaceError: Can't connect to MySQL server on '103.40.3.37:3306' (110)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/pooling.py", line 293, in connect
    return CMySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 129, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 1237, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection_cext.py", line 313, in _open_connection
    raise get_mysql_exception(
mysql.connector.errors.DatabaseError: 2003 (HY000): Can't connect to MySQL server on '103.40.3.37:3306' (110)
2023-11-17 16:21:02,866 [INFO]: Scraping and storing data completed successfully.
2023-11-17 19:01:39,489 [INFO]: package: mysql.connector.plugins
2023-11-17 19:01:39,489 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:01:39,491 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:01:41,318 [ERROR]: An error occurred: Scraper1.generate_code() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 104, in scrape_with_refcodes
    refcodes = self.generate_code(2,222000)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Scraper1.generate_code() takes 2 positional arguments but 3 were given
2023-11-17 19:02:35,629 [INFO]: package: mysql.connector.plugins
2023-11-17 19:02:35,630 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:02:35,631 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:02:41,216 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    state_el = soup.select("#state option[selected]")[1].text
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-17 19:04:11,659 [INFO]: package: mysql.connector.plugins
2023-11-17 19:04:11,660 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:04:11,664 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:15:04,206 [INFO]: package: mysql.connector.plugins
2023-11-17 19:15:04,206 [INFO]: plugin_name: caching_sha2_password
2023-11-17 19:15:04,208 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 19:54:46,324 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 119, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-17 20:02:32,798 [INFO]: package: mysql.connector.plugins
2023-11-17 20:02:32,800 [INFO]: plugin_name: caching_sha2_password
2023-11-17 20:02:32,807 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 20:57:19,732 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 48, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-17 20:59:57,344 [INFO]: package: mysql.connector.plugins
2023-11-17 20:59:57,345 [INFO]: plugin_name: caching_sha2_password
2023-11-17 20:59:57,349 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-17 21:57:45,607 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 119, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 19:28:48,167 [INFO]: package: mysql.connector.plugins
2023-11-18 19:28:48,168 [INFO]: plugin_name: caching_sha2_password
2023-11-18 19:28:48,172 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 20:26:56,014 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 120, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 21:20:44,952 [INFO]: package: mysql.connector.plugins
2023-11-18 21:20:44,952 [INFO]: plugin_name: caching_sha2_password
2023-11-18 21:20:44,955 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 21:27:24,336 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper2.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 52, in scrape_single
    state_el = soup.select("#state option[selected]")[1].text if soup.select("#state option[selected]") else None
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-18 21:28:22,157 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper2.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 52, in scrape_single
    state_el = soup.select("#state option[selected]")[1].text if soup.select("#state option[selected]") else None
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-18 22:17:46,901 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 22:18:16,792 [INFO]: package: mysql.connector.plugins
2023-11-18 22:18:16,793 [INFO]: plugin_name: caching_sha2_password
2023-11-18 22:18:16,796 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 22:18:16,805 [INFO]: package: mysql.connector.plugins
2023-11-18 22:18:16,805 [INFO]: plugin_name: mysql_native_password
2023-11-18 22:18:16,806 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-18 22:18:18,451 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 121, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 22:20:17,133 [INFO]: package: mysql.connector.plugins
2023-11-18 22:20:17,134 [INFO]: plugin_name: caching_sha2_password
2023-11-18 22:20:17,136 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 22:20:17,136 [INFO]: package: mysql.connector.plugins
2023-11-18 22:20:17,136 [INFO]: plugin_name: mysql_native_password
2023-11-18 22:20:17,137 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-18 23:04:41,604 [INFO]: package: mysql.connector.plugins
2023-11-18 23:04:41,604 [INFO]: plugin_name: caching_sha2_password
2023-11-18 23:04:41,606 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 23:18:44,575 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 122, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 52, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-18 23:26:44,597 [INFO]: package: mysql.connector.plugins
2023-11-18 23:26:44,598 [INFO]: plugin_name: caching_sha2_password
2023-11-18 23:26:44,603 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-18 23:38:42,489 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x560f0bac0fb3 <unknown>
#1 0x560f0b7944a7 <unknown>
#2 0x560f0b7c7c93 <unknown>
#3 0x560f0b7c410c <unknown>
#4 0x560f0b806ac6 <unknown>
#5 0x560f0b7fd713 <unknown>
#6 0x560f0b7d018b <unknown>
#7 0x560f0b7d0f7e <unknown>
#8 0x560f0ba868d8 <unknown>
#9 0x560f0ba8a800 <unknown>
#10 0x560f0ba94cfc <unknown>
#11 0x560f0ba8b418 <unknown>
#12 0x560f0ba5842f <unknown>
#13 0x560f0baaf4e8 <unknown>
#14 0x560f0baaf6b4 <unknown>
#15 0x560f0bac0143 <unknown>
#16 0x7f6e7d2abac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x560f0bac0fb3 <unknown>
#1 0x560f0b7944a7 <unknown>
#2 0x560f0b7c7c93 <unknown>
#3 0x560f0b7c410c <unknown>
#4 0x560f0b806ac6 <unknown>
#5 0x560f0b7fd713 <unknown>
#6 0x560f0b7d018b <unknown>
#7 0x560f0b7d0f7e <unknown>
#8 0x560f0ba868d8 <unknown>
#9 0x560f0ba8a800 <unknown>
#10 0x560f0ba94cfc <unknown>
#11 0x560f0ba8b418 <unknown>
#12 0x560f0ba5842f <unknown>
#13 0x560f0baaf4e8 <unknown>
#14 0x560f0baaf6b4 <unknown>
#15 0x560f0bac0143 <unknown>
#16 0x7f6e7d2abac3 <unknown>

2023-11-18 23:42:23,758 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5634f3a2dfb3 <unknown>
#1 0x5634f37014a7 <unknown>
#2 0x5634f3734c93 <unknown>
#3 0x5634f373110c <unknown>
#4 0x5634f3773ac6 <unknown>
#5 0x5634f376a713 <unknown>
#6 0x5634f373d18b <unknown>
#7 0x5634f373df7e <unknown>
#8 0x5634f39f38d8 <unknown>
#9 0x5634f39f7800 <unknown>
#10 0x5634f3a01cfc <unknown>
#11 0x5634f39f8418 <unknown>
#12 0x5634f39c542f <unknown>
#13 0x5634f3a1c4e8 <unknown>
#14 0x5634f3a1c6b4 <unknown>
#15 0x5634f3a2d143 <unknown>
#16 0x7f79f9550ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5634f3a2dfb3 <unknown>
#1 0x5634f37014a7 <unknown>
#2 0x5634f3734c93 <unknown>
#3 0x5634f373110c <unknown>
#4 0x5634f3773ac6 <unknown>
#5 0x5634f376a713 <unknown>
#6 0x5634f373d18b <unknown>
#7 0x5634f373df7e <unknown>
#8 0x5634f39f38d8 <unknown>
#9 0x5634f39f7800 <unknown>
#10 0x5634f3a01cfc <unknown>
#11 0x5634f39f8418 <unknown>
#12 0x5634f39c542f <unknown>
#13 0x5634f3a1c4e8 <unknown>
#14 0x5634f3a1c6b4 <unknown>
#15 0x5634f3a2d143 <unknown>
#16 0x7f79f9550ac3 <unknown>

2023-11-18 23:43:19,887 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x561825804fb3 <unknown>
#1 0x5618254d84a7 <unknown>
#2 0x56182550bc93 <unknown>
#3 0x56182550810c <unknown>
#4 0x56182554aac6 <unknown>
#5 0x561825541713 <unknown>
#6 0x56182551418b <unknown>
#7 0x561825514f7e <unknown>
#8 0x5618257ca8d8 <unknown>
#9 0x5618257ce800 <unknown>
#10 0x5618257d8cfc <unknown>
#11 0x5618257cf418 <unknown>
#12 0x56182579c42f <unknown>
#13 0x5618257f34e8 <unknown>
#14 0x5618257f36b4 <unknown>
#15 0x561825804143 <unknown>
#16 0x7fe137274ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x561825804fb3 <unknown>
#1 0x5618254d84a7 <unknown>
#2 0x56182550bc93 <unknown>
#3 0x56182550810c <unknown>
#4 0x56182554aac6 <unknown>
#5 0x561825541713 <unknown>
#6 0x56182551418b <unknown>
#7 0x561825514f7e <unknown>
#8 0x5618257ca8d8 <unknown>
#9 0x5618257ce800 <unknown>
#10 0x5618257d8cfc <unknown>
#11 0x5618257cf418 <unknown>
#12 0x56182579c42f <unknown>
#13 0x5618257f34e8 <unknown>
#14 0x5618257f36b4 <unknown>
#15 0x561825804143 <unknown>
#16 0x7fe137274ac3 <unknown>

2023-11-19 00:00:28,805 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5620a519b5e3 <unknown>
#1 0x5620a4e5e0b7 <unknown>
#2 0x5620a4e94e55 <unknown>
#3 0x5620a4e91b81 <unknown>
#4 0x5620a4edc47f <unknown>
#5 0x5620a4ed2cc3 <unknown>
#6 0x5620a4e9e0e4 <unknown>
#7 0x5620a4e9f0ae <unknown>
#8 0x5620a5161ce1 <unknown>
#9 0x5620a5165b7e <unknown>
#10 0x5620a514f4b5 <unknown>
#11 0x5620a51667d6 <unknown>
#12 0x5620a5132dbf <unknown>
#13 0x5620a5189748 <unknown>
#14 0x5620a5189917 <unknown>
#15 0x5620a519a773 <unknown>
#16 0x7fc4a185fac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5620a519b5e3 <unknown>
#1 0x5620a4e5e0b7 <unknown>
#2 0x5620a4e94e55 <unknown>
#3 0x5620a4e91b81 <unknown>
#4 0x5620a4edc47f <unknown>
#5 0x5620a4ed2cc3 <unknown>
#6 0x5620a4e9e0e4 <unknown>
#7 0x5620a4e9f0ae <unknown>
#8 0x5620a5161ce1 <unknown>
#9 0x5620a5165b7e <unknown>
#10 0x5620a514f4b5 <unknown>
#11 0x5620a51667d6 <unknown>
#12 0x5620a5132dbf <unknown>
#13 0x5620a5189748 <unknown>
#14 0x5620a5189917 <unknown>
#15 0x5620a519a773 <unknown>
#16 0x7fc4a185fac3 <unknown>

2023-11-19 00:03:09,893 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55cded7fe5e3 <unknown>
#1 0x55cded4c10b7 <unknown>
#2 0x55cded4f7e55 <unknown>
#3 0x55cded4f4b81 <unknown>
#4 0x55cded53f47f <unknown>
#5 0x55cded535cc3 <unknown>
#6 0x55cded5010e4 <unknown>
#7 0x55cded5020ae <unknown>
#8 0x55cded7c4ce1 <unknown>
#9 0x55cded7c8b7e <unknown>
#10 0x55cded7b24b5 <unknown>
#11 0x55cded7c97d6 <unknown>
#12 0x55cded795dbf <unknown>
#13 0x55cded7ec748 <unknown>
#14 0x55cded7ec917 <unknown>
#15 0x55cded7fd773 <unknown>
#16 0x7fed6c7c4ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55cded7fe5e3 <unknown>
#1 0x55cded4c10b7 <unknown>
#2 0x55cded4f7e55 <unknown>
#3 0x55cded4f4b81 <unknown>
#4 0x55cded53f47f <unknown>
#5 0x55cded535cc3 <unknown>
#6 0x55cded5010e4 <unknown>
#7 0x55cded5020ae <unknown>
#8 0x55cded7c4ce1 <unknown>
#9 0x55cded7c8b7e <unknown>
#10 0x55cded7b24b5 <unknown>
#11 0x55cded7c97d6 <unknown>
#12 0x55cded795dbf <unknown>
#13 0x55cded7ec748 <unknown>
#14 0x55cded7ec917 <unknown>
#15 0x55cded7fd773 <unknown>
#16 0x7fed6c7c4ac3 <unknown>

2023-11-19 00:05:45,508 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5611d7f455e3 <unknown>
#1 0x5611d7c080b7 <unknown>
#2 0x5611d7c3ee55 <unknown>
#3 0x5611d7c3bb81 <unknown>
#4 0x5611d7c8647f <unknown>
#5 0x5611d7c7ccc3 <unknown>
#6 0x5611d7c480e4 <unknown>
#7 0x5611d7c490ae <unknown>
#8 0x5611d7f0bce1 <unknown>
#9 0x5611d7f0fb7e <unknown>
#10 0x5611d7ef94b5 <unknown>
#11 0x5611d7f107d6 <unknown>
#12 0x5611d7edcdbf <unknown>
#13 0x5611d7f33748 <unknown>
#14 0x5611d7f33917 <unknown>
#15 0x5611d7f44773 <unknown>
#16 0x7f08c6eb4ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5611d7f455e3 <unknown>
#1 0x5611d7c080b7 <unknown>
#2 0x5611d7c3ee55 <unknown>
#3 0x5611d7c3bb81 <unknown>
#4 0x5611d7c8647f <unknown>
#5 0x5611d7c7ccc3 <unknown>
#6 0x5611d7c480e4 <unknown>
#7 0x5611d7c490ae <unknown>
#8 0x5611d7f0bce1 <unknown>
#9 0x5611d7f0fb7e <unknown>
#10 0x5611d7ef94b5 <unknown>
#11 0x5611d7f107d6 <unknown>
#12 0x5611d7edcdbf <unknown>
#13 0x5611d7f33748 <unknown>
#14 0x5611d7f33917 <unknown>
#15 0x5611d7f44773 <unknown>
#16 0x7f08c6eb4ac3 <unknown>

2023-11-19 00:07:03,572 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55be06f825e3 <unknown>
#1 0x55be06c450b7 <unknown>
#2 0x55be06c7be55 <unknown>
#3 0x55be06c78b81 <unknown>
#4 0x55be06cc347f <unknown>
#5 0x55be06cb9cc3 <unknown>
#6 0x55be06c850e4 <unknown>
#7 0x55be06c860ae <unknown>
#8 0x55be06f48ce1 <unknown>
#9 0x55be06f4cb7e <unknown>
#10 0x55be06f364b5 <unknown>
#11 0x55be06f4d7d6 <unknown>
#12 0x55be06f19dbf <unknown>
#13 0x55be06f70748 <unknown>
#14 0x55be06f70917 <unknown>
#15 0x55be06f81773 <unknown>
#16 0x7faf8bf66ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55be06f825e3 <unknown>
#1 0x55be06c450b7 <unknown>
#2 0x55be06c7be55 <unknown>
#3 0x55be06c78b81 <unknown>
#4 0x55be06cc347f <unknown>
#5 0x55be06cb9cc3 <unknown>
#6 0x55be06c850e4 <unknown>
#7 0x55be06c860ae <unknown>
#8 0x55be06f48ce1 <unknown>
#9 0x55be06f4cb7e <unknown>
#10 0x55be06f364b5 <unknown>
#11 0x55be06f4d7d6 <unknown>
#12 0x55be06f19dbf <unknown>
#13 0x55be06f70748 <unknown>
#14 0x55be06f70917 <unknown>
#15 0x55be06f81773 <unknown>
#16 0x7faf8bf66ac3 <unknown>

2023-11-19 00:07:10,333 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5631064d25e3 <unknown>
#1 0x5631061950b7 <unknown>
#2 0x5631061cbe55 <unknown>
#3 0x5631061c8b81 <unknown>
#4 0x56310621347f <unknown>
#5 0x563106209cc3 <unknown>
#6 0x5631061d50e4 <unknown>
#7 0x5631061d60ae <unknown>
#8 0x563106498ce1 <unknown>
#9 0x56310649cb7e <unknown>
#10 0x5631064864b5 <unknown>
#11 0x56310649d7d6 <unknown>
#12 0x563106469dbf <unknown>
#13 0x5631064c0748 <unknown>
#14 0x5631064c0917 <unknown>
#15 0x5631064d1773 <unknown>
#16 0x7f8c4d05eac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 208, in __init__
    self.start_session(capabilities)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 292, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5631064d25e3 <unknown>
#1 0x5631061950b7 <unknown>
#2 0x5631061cbe55 <unknown>
#3 0x5631061c8b81 <unknown>
#4 0x56310621347f <unknown>
#5 0x563106209cc3 <unknown>
#6 0x5631061d50e4 <unknown>
#7 0x5631061d60ae <unknown>
#8 0x563106498ce1 <unknown>
#9 0x56310649cb7e <unknown>
#10 0x5631064864b5 <unknown>
#11 0x56310649d7d6 <unknown>
#12 0x563106469dbf <unknown>
#13 0x5631064c0748 <unknown>
#14 0x5631064c0917 <unknown>
#15 0x5631064d1773 <unknown>
#16 0x7f8c4d05eac3 <unknown>

2023-11-19 00:24:12,171 [ERROR]: An error occurred: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x557056c8a5e3 <unknown>
#1 0x55705694d0b7 <unknown>
#2 0x557056983e55 <unknown>
#3 0x557056980b81 <unknown>
#4 0x5570569cb47f <unknown>
#5 0x5570569c1cc3 <unknown>
#6 0x55705698d0e4 <unknown>
#7 0x55705698e0ae <unknown>
#8 0x557056c50ce1 <unknown>
#9 0x557056c54b7e <unknown>
#10 0x557056c3e4b5 <unknown>
#11 0x557056c557d6 <unknown>
#12 0x557056c21dbf <unknown>
#13 0x557056c78748 <unknown>
#14 0x557056c78917 <unknown>
#15 0x557056c89773 <unknown>
#16 0x7f4d23851ac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 18, in main
    scraper1 = Scraper3()
               ^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 13, in __init__
    self.br = self.get_browser()
              ^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 162, in get_browser
    browser = webdriver.Chrome(options=chrome_options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
    super().__init__(
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 56, in __init__
    super().__init__(
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 205, in __init__
    self.start_session(capabilities)
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 289, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    self.error_handler.check_response(response)
  File "/root/venv/selenium/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.SessionNotCreatedException: Message: session not created: Chrome failed to start: exited normally.
  (session not created: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x557056c8a5e3 <unknown>
#1 0x55705694d0b7 <unknown>
#2 0x557056983e55 <unknown>
#3 0x557056980b81 <unknown>
#4 0x5570569cb47f <unknown>
#5 0x5570569c1cc3 <unknown>
#6 0x55705698d0e4 <unknown>
#7 0x55705698e0ae <unknown>
#8 0x557056c50ce1 <unknown>
#9 0x557056c54b7e <unknown>
#10 0x557056c3e4b5 <unknown>
#11 0x557056c557d6 <unknown>
#12 0x557056c21dbf <unknown>
#13 0x557056c78748 <unknown>
#14 0x557056c78917 <unknown>
#15 0x557056c89773 <unknown>
#16 0x7f4d23851ac3 <unknown>

2023-11-19 00:25:12,596 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 31, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper1.py", line 123, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    address_el = soup.select_one("#address")['value'] if soup.select_one("#address")['value'] else None
                                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 00:25:29,616 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler_local.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-19 00:25:38,386 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 25, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler_local.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/selenium/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-19 00:27:32,892 [ERROR]: An error occurred: 'WebDriverWait' object has no attribute 'get'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    self.br.get(url)
    ^^^^^^^^^^^
AttributeError: 'WebDriverWait' object has no attribute 'get'
2023-11-19 00:28:50,600 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 57, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 00:29:06,056 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 125, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 57, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-19 00:33:08,150 [ERROR]: An error occurred: Message: 
Stacktrace:
#0 0x55d42dbae5e3 <unknown>
#1 0x55d42d8710b7 <unknown>
#2 0x55d42d8bef53 <unknown>
#3 0x55d42d8bf051 <unknown>
#4 0x55d42d9049c4 <unknown>
#5 0x55d42d8e5f1d <unknown>
#6 0x55d42d901b3d <unknown>
#7 0x55d42d8e5cc3 <unknown>
#8 0x55d42d8b10e4 <unknown>
#9 0x55d42d8b20ae <unknown>
#10 0x55d42db74ce1 <unknown>
#11 0x55d42db78b7e <unknown>
#12 0x55d42db624b5 <unknown>
#13 0x55d42db797d6 <unknown>
#14 0x55d42db45dbf <unknown>
#15 0x55d42db9c748 <unknown>
#16 0x55d42db9c917 <unknown>
#17 0x55d42dbad773 <unknown>
#18 0x7f5f9482bac3 <unknown>
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 129, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 52, in scrape_single
    WebDriverWait(self.br,5).until(EC.presence_of_element_located((By.NAME,"wpforms[fields][1][first]")))
  File "/root/venv/corey/lib/python3.12/site-packages/selenium/webdriver/support/wait.py", line 101, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Stacktrace:
#0 0x55d42dbae5e3 <unknown>
#1 0x55d42d8710b7 <unknown>
#2 0x55d42d8bef53 <unknown>
#3 0x55d42d8bf051 <unknown>
#4 0x55d42d9049c4 <unknown>
#5 0x55d42d8e5f1d <unknown>
#6 0x55d42d901b3d <unknown>
#7 0x55d42d8e5cc3 <unknown>
#8 0x55d42d8b10e4 <unknown>
#9 0x55d42d8b20ae <unknown>
#10 0x55d42db74ce1 <unknown>
#11 0x55d42db78b7e <unknown>
#12 0x55d42db624b5 <unknown>
#13 0x55d42db797d6 <unknown>
#14 0x55d42db45dbf <unknown>
#15 0x55d42db9c748 <unknown>
#16 0x55d42db9c917 <unknown>
#17 0x55d42dbad773 <unknown>
#18 0x7f5f9482bac3 <unknown>

2023-11-19 00:34:06,028 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main_test.py", line 33, in main
    for batch_results in scraper1.scrape_with_refcodes():#refcodes_file)
  File "/root/projects/corey/src/scraping/scraper3.py", line 131, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 63, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
