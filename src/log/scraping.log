2023-11-15 17:23:29,975 [ERROR]: An error occurred: [Errno 2] No such file or directory: 'refcodes.txt'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 68, in scrape_with_refcodes
    with open(refcodes_file,'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'refcodes.txt'
2023-11-15 17:24:08,961 [ERROR]: An error occurred: 'Scraper1' object has no attribute 'url'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
                                ^^^^^^^^
AttributeError: 'Scraper1' object has no attribute 'url'
2023-11-15 17:24:38,086 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:24:59,862 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:30:50,656 [ERROR]: An error occurred: 'NoneType' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 77, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 37, in scrape_single
    first_name = soup.find('div',{'class':'first-name'}).text.strip()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'text'
2023-11-15 17:41:01,449 [ERROR]: An error occurred: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 106, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 51, in scrape_single
    first_name = first_name_el.text.strip()
                 ^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 2428, in __getattr__
    raise AttributeError(
AttributeError: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
2023-11-15 17:47:19,951 [INFO]: package: mysql.connector.plugins
2023-11-15 17:47:19,951 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:47:19,952 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:47:19,954 [ERROR]: An error occurred: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AUTOINCREMENT,
                                first_name VARCHAR(255),
        ' at line 2
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 28, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 16, in __init__
    self.cursor.execute('''
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/cursor.py", line 617, in execute
    self._handle_result(self._connection.cmd_query(stmt))
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/opentelemetry/context_propagation.py", line 77, in wrapper
    return method(cnx, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 1069, in cmd_query
    result = self._handle_result(self._send_cmd(ServerCmd.QUERY, query))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mysql/connector/connection.py", line 846, in _handle_result
    raise get_exception(packet)
mysql.connector.errors.ProgrammingError: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AUTOINCREMENT,
                                first_name VARCHAR(255),
        ' at line 2
2023-11-15 17:49:13,074 [INFO]: package: mysql.connector.plugins
2023-11-15 17:49:13,075 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:49:13,076 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:49:13,109 [ERROR]: An error occurred: 'firstname'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 37, in main
    db_handler.store_data(data1)
  File "/root/projects/corey/src/database/database_handler.py", line 38, in store_data
    ''', (data['firstname'], data['last_name'], data['address'], data['city'], data['state'], data['zip_code']))
          ~~~~^^^^^^^^^^^^^
KeyError: 'firstname'
2023-11-15 17:50:13,096 [INFO]: package: mysql.connector.plugins
2023-11-15 17:50:13,096 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:50:13,097 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:50:13,111 [INFO]: Scraping and storing data completed successfully.
2023-11-15 17:51:05,400 [INFO]: package: mysql.connector.plugins
2023-11-15 17:51:05,401 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:51:05,401 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:51:05,414 [INFO]: Scraping and storing data completed successfully.
2023-11-15 17:59:32,010 [INFO]: package: mysql.connector.plugins
2023-11-15 17:59:32,011 [INFO]: plugin_name: caching_sha2_password
2023-11-15 17:59:32,011 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-15 17:59:32,024 [INFO]: Scraping and storing data completed successfully.
2023-11-15 18:38:21,721 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:38:43,037 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:41:36,095 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:42:55,182 [ERROR]: An error occurred: Authentication plugin 'caching_sha2_password' is not supported
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 29, in main
    db_handler = DatabaseHandler(
                 ^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/database/database_handler.py", line 6, in __init__
    self.conn = mysql.connector.connect(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/__init__.py", line 179, in connect
    return MySQLConnection(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 95, in __init__
    self.connect(**kwargs)
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/abstracts.py", line 716, in connect
    self._open_connection()
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 208, in _open_connection
    self._do_auth(self._user, self._password,
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/connection.py", line 137, in _do_auth
    packet = self._protocol.make_auth(
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 99, in make_auth
    packet += self._auth_response(client_flags, username, password,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/protocol.py", line 58, in _auth_response
    auth = get_auth_plugin(auth_plugin)(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/corey/lib/python3.12/site-packages/mysql/connector/authentication.py", line 190, in get_auth_plugin
    raise errors.NotSupportedError(
mysql.connector.errors.NotSupportedError: Authentication plugin 'caching_sha2_password' is not supported
2023-11-15 18:45:05,663 [INFO]: Scraping and storing data completed successfully.
2023-11-15 19:05:35,285 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 25, in main
    data1 = scraper2.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-15 19:18:14,921 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 24, in main
    data1 = scraper3.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:08:33,995 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 106, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 43, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:09:23,556 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 44, in scrape_single
    first_name_el = soup.select("body > section > div.position-relative > div > div > div > div > div.pt-5.fs-3.text-dark > a")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 08:25:10,553 [INFO]: package: mysql.connector.plugins
2023-11-16 08:25:10,554 [INFO]: plugin_name: caching_sha2_password
2023-11-16 08:25:10,555 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 08:25:10,556 [INFO]: package: mysql.connector.plugins
2023-11-16 08:25:10,556 [INFO]: plugin_name: mysql_native_password
2023-11-16 08:25:10,556 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 08:25:10,580 [INFO]: Scraping and storing data completed successfully.
2023-11-16 09:17:36,515 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 107, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 44, in scrape_single
    first_name_el = soup.select("#firstName")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 09:29:03,882 [ERROR]: An error occurred: list index out of range
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 50, in scrape_single
    first_name_el = soup.select("#firstName")[0]
                    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
2023-11-16 09:40:28,653 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 35, in scrape_single
    csrf_token = soup.find('meta',{'name':'csrf-token'})['content']
                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 09:43:06,185 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 126, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 63, in scrape_single
    first_name_el = soup.select_one("#firstName")['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 10:05:00,405 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:06:21,463 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:08:38,495 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 96, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:14:16,485 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:14:24,397 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:15:02,047 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:16:18,216 [ERROR]: An error occurred: Failed to retrieve data. Status code: 201
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 97, in scrape_single
    raise Exception(f"Failed to retrieve data. Status code: {response.status_code}")
Exception: Failed to retrieve data. Status code: 201
2023-11-16 10:17:25,488 [ERROR]: An error occurred: 'value'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    state_el = soup.select_one("#state")['value']
               ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 'value'
2023-11-16 10:20:20,948 [ERROR]: An error occurred: 'str' object has no attribute 'text'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 53, in scrape_single
    first_name = first_name_el.text.strip()
                 ^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'text'
2023-11-16 10:21:37,887 [INFO]: package: mysql.connector.plugins
2023-11-16 10:21:37,887 [INFO]: plugin_name: caching_sha2_password
2023-11-16 10:21:37,887 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 10:21:37,888 [INFO]: package: mysql.connector.plugins
2023-11-16 10:21:37,888 [INFO]: plugin_name: mysql_native_password
2023-11-16 10:21:37,888 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 10:21:37,903 [INFO]: Scraping and storing data completed successfully.
2023-11-16 10:25:06,304 [ERROR]: An error occurred: 1
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 22, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper1.py", line 49, in scrape_single
    state_el = soup.select_one("#state option[selected]")[1].text
               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/bs4/element.py", line 1573, in __getitem__
    return self.attrs[key]
           ~~~~~~~~~~^^^^^
KeyError: 1
2023-11-16 10:30:58,571 [INFO]: package: mysql.connector.plugins
2023-11-16 10:30:58,571 [INFO]: plugin_name: caching_sha2_password
2023-11-16 10:30:58,572 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 10:30:58,572 [INFO]: package: mysql.connector.plugins
2023-11-16 10:30:58,573 [INFO]: plugin_name: mysql_native_password
2023-11-16 10:30:58,573 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 10:30:58,583 [INFO]: Scraping and storing data completed successfully.
2023-11-16 15:22:02,532 [INFO]: package: mysql.connector.plugins
2023-11-16 15:22:02,533 [INFO]: plugin_name: caching_sha2_password
2023-11-16 15:22:02,533 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLCachingSHA2PasswordAuthPlugin
2023-11-16 15:22:02,534 [INFO]: package: mysql.connector.plugins
2023-11-16 15:22:02,534 [INFO]: plugin_name: mysql_native_password
2023-11-16 15:22:02,534 [INFO]: AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
2023-11-16 15:22:02,547 [INFO]: Scraping and storing data completed successfully.
2023-11-16 16:22:41,568 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper2.py", line 46, in scrape_single
    first_name_el = soup.select_one("#firstName")['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:23:11,993 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:23:31,118 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:32:41,969 [ERROR]: An error occurred: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 115, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 39, in scrape_single
    response = requests.post(url, headers=headers, data=data, allow_redirects=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 575, in request
    prep = self.prepare_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/sessions.py", line 486, in prepare_request
    p.prepare(
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 369, in prepare
    self.prepare_headers(headers)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/models.py", line 491, in prepare_headers
    check_header_validity(header)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1039, in check_header_validity
    _validate_header_part(header, name, 0)
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/utils.py", line 1056, in _validate_header_part
    raise InvalidHeader(
requests.exceptions.InvalidHeader: Invalid leading whitespace, reserved character(s), or returncharacter(s) in header name: ':authority'
2023-11-16 16:34:59,917 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 109, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 43, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:43:37,734 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 110, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 44, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:56:05,608 [ERROR]: An error occurred: 'Response' object has no attribute 'header'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    redirect_url = response.header['Location']
                   ^^^^^^^^^^^^^^^
AttributeError: 'Response' object has no attribute 'header'. Did you mean: 'headers'?
2023-11-16 16:56:28,219 [ERROR]: An error occurred: 'location'
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 35, in scrape_single
    redirect_url = response.headers['Location']
                   ~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.12.0/lib/python3.12/site-packages/requests/structures.py", line 52, in __getitem__
    return self._store[key.lower()][1]
           ~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'location'
2023-11-16 16:57:11,265 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 46, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 16:58:18,626 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 112, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 46, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:04:17,928 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:05:03,972 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:20:48,915 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 116, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 50, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:21:24,353 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:27:40,451 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 117, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 51, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:29:10,556 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 48, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:31:25,821 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 114, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 48, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:41:34,966 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 118, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 52, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:56:45,530 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 17:57:05,786 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 108, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 42, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:08:22,932 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:09:11,792 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:10:45,775 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:12:03,399 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 113, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 47, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:24:37,965 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:25:28,105 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
2023-11-16 18:25:59,854 [ERROR]: An error occurred: 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/root/projects/corey/src/main.py", line 23, in main
    data1 = scraper1.scrape_with_refcodes(refcodes_file)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 111, in scrape_with_refcodes
    result = self.scrape_single(self.url,data)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/projects/corey/src/scraping/scraper3.py", line 45, in scrape_single
    first_name_el = soup.find(attrs={'name':'wpforms[fields][1][first]'})['value']
                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
TypeError: 'NoneType' object is not subscriptable
